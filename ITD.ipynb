{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK-ONXiYqxMW"
      },
      "source": [
        "# **Infrared Thermal Dataset**\n",
        "A low-resolution infrared thermal dataset of people and thermal objects, such as a working laptop, in indoor environments. The dataset was collected by a far infrared thermal camera (32x24 pixels), which can capture the position and shape information of thermal objects without privacy issues that enable trustworthy computer vision applications. The dataset consists of 1770 thermal images with high-quality annotation collected from an indoor room with around 15°C.\n",
        "\n",
        "Shuai Zhu, Thiemo Voigt, Daniel F. Perez-Ramirez, and Joakim Eriksson. 2021. A Low-resolution infrared thermal dataset and potential privacy-preserving applications. In Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems (SenSys '21). Association for Computing Machinery, New York, NY, USA, 552–555. https://doi.org/10.1145/3485730.3493692\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZvDBg5SqxMY"
      },
      "source": [
        "# **Download dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3h56MAZ-Qis"
      },
      "outputs": [],
      "source": [
        "!wget https://zenodo.org/records/5574233/files/Infrared%20thermal%20dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ww6v4WDm76Q"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"./Infrared thermal dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYbC3rCtnUyl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def gen_4_classes(xml_directory, image_directory, destination_directory):\n",
        "    # Define the destination directories for each classification\n",
        "    destinations = {\n",
        "        'one_person': 'one_person',\n",
        "        'two_people': 'two_people',\n",
        "        'objects': 'objects',\n",
        "        'people_and_objects': 'people_and_objects'\n",
        "    }\n",
        "\n",
        "    # Create destination directories if they do not exist\n",
        "    for dest in destinations.values():\n",
        "        os.makedirs(os.path.join(destination_directory, dest), exist_ok=True)\n",
        "\n",
        "    # List all XML files in the source directory\n",
        "    xml_files = [f for f in os.listdir(xml_directory) if f.endswith('.xml')]\n",
        "\n",
        "    for xml_file in xml_files:\n",
        "        print(f'Processing {xml_file}...')\n",
        "        tree = ET.parse(os.path.join(xml_directory, xml_file))\n",
        "        root = tree.getroot()\n",
        "\n",
        "        person_count = 0\n",
        "        other_objects = False\n",
        "\n",
        "        # Count 'person' objects and identify other objects\n",
        "        for obj in root.findall('object'):\n",
        "            obj_name = obj.find('name').text\n",
        "            if obj_name == 'person':\n",
        "                person_count += 1\n",
        "            else:\n",
        "                other_objects = True\n",
        "\n",
        "        # Determine the classification\n",
        "        if person_count == 1 and not other_objects:\n",
        "            classification = 'one_person'\n",
        "        elif person_count > 1 and not other_objects:\n",
        "            classification = 'two_people'\n",
        "        elif other_objects and person_count == 0:\n",
        "            classification = 'objects'\n",
        "        else:  # other_objects and person_count >= 1\n",
        "            classification = 'people_and_objects'\n",
        "\n",
        "        # Construct the filename for the related image from the XML filename\n",
        "        image_filename = xml_file.replace('.xml', '.png')\n",
        "        source_path = os.path.join(image_directory, image_filename)\n",
        "        destination_path = os.path.join(destination_directory, destinations[classification], image_filename)\n",
        "\n",
        "        # Move the image file to the corresponding directory\n",
        "        if os.path.exists(source_path):\n",
        "            shutil.copy(source_path, destination_path)\n",
        "            print(f'Copied {image_filename} to {destinations[classification]}/')\n",
        "\n",
        "\n",
        "def gen_2_classes(xml_directory, image_directory, destination_directory):\n",
        "    # Define the destination directories for each classification\n",
        "    destinations = {\n",
        "        'occupied': 'occupied',\n",
        "        'unoccupied': 'unoccupied',\n",
        "    }\n",
        "\n",
        "    # Create destination directories if they do not exist\n",
        "    for dest in destinations.values():\n",
        "        os.makedirs(os.path.join(destination_directory, dest), exist_ok=True)\n",
        "\n",
        "    # List all XML files in the source directory\n",
        "    xml_files = [f for f in os.listdir(xml_directory) if f.endswith('.xml')]\n",
        "\n",
        "    for xml_file in xml_files:\n",
        "        # print(f'Processing {xml_file}...')\n",
        "        tree = ET.parse(os.path.join(xml_directory, xml_file))\n",
        "        root = tree.getroot()\n",
        "\n",
        "        presence = False\n",
        "\n",
        "        # Count 'person' objects and identify other objects\n",
        "        for obj in root.findall('object'):\n",
        "            obj_name = obj.find('name').text\n",
        "            if obj_name == 'person':\n",
        "                presence = True\n",
        "                break\n",
        "\n",
        "        # Determine the classification\n",
        "        if presence:\n",
        "            classification = 'occupied'\n",
        "        else:\n",
        "            classification = 'unoccupied'\n",
        "\n",
        "        # Construct the filename for the related image from the XML filename\n",
        "        image_filename = xml_file.replace('.xml', '.png')\n",
        "        source_path = os.path.join(image_directory, image_filename)\n",
        "        destination_path = os.path.join(destination_directory, destinations[classification], image_filename)\n",
        "\n",
        "        # Move the image file to the corresponding directory\n",
        "        if os.path.exists(source_path):\n",
        "            shutil.copy(source_path, destination_path)\n",
        "            # print(f'Copied {image_filename} to {destinations[classification]}/')\n",
        "\n",
        "\n",
        "xml_directory = './Reshaped Data(640by640)/Data annotation'\n",
        "image_directory = './Original Data(32by24)'\n",
        "new_image_directory = './4classes'\n",
        "gen_4_classes(xml_directory, image_directory, new_image_directory)\n",
        "# new_image_directory = './2classes'\n",
        "# gen_2_classes(xml_directory, image_directory, new_image_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwCf23kBJFz_"
      },
      "outputs": [],
      "source": [
        "# Optional, use this cell to augment the dataset\n",
        "\n",
        "!pip install -q Augmentor\n",
        "import Augmentor\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np.array(data['target'])\n",
        "    return files, targets\n",
        "\n",
        "def augment_class(class_directory, num_to_generate):\n",
        "    p = Augmentor.Pipeline(class_directory, output_directory=\"output\")\n",
        "    # p.rotate(probability=0.3, max_left_rotation=8, max_right_rotation=8)\n",
        "    p.flip_left_right(probability=0.5)\n",
        "    p.zoom(probability=0.2, min_factor=1.1, max_factor=1.3)\n",
        "    # p.flip_top_bottom(probability=0.5)\n",
        "    p.sample(num_to_generate)\n",
        "\n",
        "    # Move and rename the augmented files\n",
        "    output_directory = os.path.join(class_directory, \"output\")\n",
        "    for file in os.listdir(output_directory):\n",
        "        src = os.path.join(output_directory, file)\n",
        "        new_filename = \"augmented_\" + file\n",
        "        dst = os.path.join(class_directory, new_filename)\n",
        "        shutil.move(src, dst)\n",
        "    os.rmdir(output_directory)\n",
        "\n",
        "# Load dataset\n",
        "files, targets = load_dataset('./4classes')\n",
        "\n",
        "# Determine the number of samples needed for each class to balance the dataset\n",
        "num_samples_per_class = max(np.bincount(targets))\n",
        "augment_factors = num_samples_per_class - np.bincount(targets)\n",
        "\n",
        "# Augment each class as needed\n",
        "for class_index in range(len(augment_factors)):\n",
        "    class_files = files[targets == class_index]\n",
        "    if augment_factors[class_index] > 0:\n",
        "        class_directory = os.path.dirname(class_files[0])  # Assuming all files of a class are in a single directory\n",
        "        augment_class(class_directory, augment_factors[class_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znN9ERRKZpap"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "dataset = sklearn.datasets.load_files('./4classes', shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j8ppLxnqxMa"
      },
      "source": [
        "Check the number of samples (should be 4324):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqQ6aKsSqxMa"
      },
      "outputs": [],
      "source": [
        "samples_number = len(dataset.data)\n",
        "print(\"Number of samples: \", samples_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIUQ0G5qxMa"
      },
      "source": [
        "Pre-process files content in order to convert bytes images into array of RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4werPLuqxMb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "for index, data in enumerate(dataset.data) :\n",
        "    image_bytesio = io.BytesIO(data)\n",
        "    image = Image.open(image_bytesio)\n",
        "    image_array = np.array(image)\n",
        "    image_array=image_array[:, :, :3]\n",
        "    dataset.data[index]=image_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyn-YRKQqxMb"
      },
      "source": [
        "Show some sample as a RGB image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF3qKa8uqxMb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "fig = plt.figure(figsize=(24, 32))\n",
        "columns = 4\n",
        "rows = 5\n",
        "\n",
        "for i in range(1, columns*rows +1):\n",
        "    index = random.randint(0, samples_number)\n",
        "    img = dataset.data[index]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(str(dataset.target[index]), fontsize=8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zku4ylweqxMb"
      },
      "source": [
        "Prepare the dataset for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRa_Y7wBqxMb"
      },
      "outputs": [],
      "source": [
        "X = np.array(dataset.data)\n",
        "y = np.array(dataset.target)\n",
        "print(\"Shape X: \", X.shape)\n",
        "print(\"Shape y: \", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHWWKneFt1JV"
      },
      "source": [
        "Get the **height**, **width** and **number of channels** of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCLHFd-M3IzC"
      },
      "outputs": [],
      "source": [
        "height, width, number_of_channels = X[0].shape\n",
        "print(height,width,number_of_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08rjB07ZqxMc"
      },
      "source": [
        "The  classes are balanced, so accuracy is a good metric to use\n",
        "Preprocessing and Spliting the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUG_p07arS3S"
      },
      "outputs": [],
      "source": [
        "X = np.array(dataset.data)\n",
        "y = np.array(dataset.target)\n",
        "\n",
        "train_size=int(len(dataset.data) * 0.85)\n",
        "X_train_full, X_test, y_train_full, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]\n",
        "\n",
        "val_size= int(len(dataset.data) * 0.15)\n",
        "X_valid, X_train = X_train_full[:val_size], X_train_full[val_size:]\n",
        "y_valid, y_train = y_train_full[:val_size], y_train_full[val_size:]\n",
        "\n",
        "print('Training set:', X_train.shape, y_train.shape)\n",
        "print('Validation set:', X_valid.shape, y_valid.shape)\n",
        "print('Test set:', X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNLyrhnVFNTu"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    print(\"Training samples number \" + str(i) + \" :\", np.count_nonzero(y_train == i))\n",
        "    print(\"Validation samples number \" + str(i) + \" :\", np.count_nonzero(y_valid == i))\n",
        "    print(\"Test samples number\" + str(i) + \" :\", np.count_nonzero(y_test == i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBOkrCGgcVKO"
      },
      "outputs": [],
      "source": [
        "linear_classifier_accuracy=[]\n",
        "MLP_classifier_accuracy=[]\n",
        "CNN_classifier_accuracy=[]\n",
        "DCNN_classifier_accuracy=[]\n",
        "NN_model_sizes=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ou5uc7qxMe"
      },
      "source": [
        "# **NN models**\n",
        "In this section we implement all general functions that can be used by all NN models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9qUtpPD_W-e"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB7nai7BvswP"
      },
      "source": [
        "Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJp04gZRsHAe"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-optimize\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "import tracemalloc\n",
        "import sklearn\n",
        "from keras.backend import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import BayesianOptimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i1nNvyeXnNq"
      },
      "outputs": [],
      "source": [
        "epochs=200\n",
        "batch_size=32\n",
        "def NN_hyperparameter_fit(hyperparameter,Type_model):\n",
        "  if (Type_model==\"CNN\"):\n",
        "    model=build_model(hyperparameter)\n",
        "  if (Type_model==\"DCNN\"):\n",
        "    model=build_model_DCC(hyperparameter)\n",
        "  model.summary()\n",
        "  history = model.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
        "  plot_model_performance(history,epochs)\n",
        "  return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttTm2IKkZqaT"
      },
      "outputs": [],
      "source": [
        "def ML_hyperparameters_study(classifier, param_grid, X_train_ML, X_test_ML, y_train_full_ML, y_test_full_ML,random=False):\n",
        "    classifier.random_state = 42\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=5, verbose=1)\n",
        "    grid_search.fit(X_train_ML, y_train_full_ML)\n",
        "    results = grid_search.cv_results_\n",
        "    mean_training_score_all = []\n",
        "    params_all = []\n",
        "    testing_accuracy = []\n",
        "    models_size = []\n",
        "    execution_time_list = []\n",
        "    total_allocated_memory=[]\n",
        "    average_allocated_memory=[]\n",
        "    precision_list, recall_list, f1_score_list=[],[],[]\n",
        "\n",
        "    def fit_and_measure_memory(model, X_train_ML, y_train_full_ML):\n",
        "      tracemalloc.start()\n",
        "      start_time = time.time()\n",
        "      model.fit(X_train_ML, y_train_full_ML)\n",
        "      snapshot = tracemalloc.take_snapshot()\n",
        "      tracemalloc.stop()\n",
        "      end_time = time.time()\n",
        "      execution_time_list.append(end_time - start_time)\n",
        "      return snapshot\n",
        "\n",
        "    for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
        "        mean_training_score_all.append(mean_score)\n",
        "        params_all.append(params)\n",
        "        hyper_model = classifier\n",
        "        if random:\n",
        "            hyper_model.random_state = 42\n",
        "        hyper_model.set_params(**params)\n",
        "        snap = fit_and_measure_memory(hyper_model, X_train_ML, y_train_full_ML)\n",
        "        # Calculate the total allocated memory from the snapshot\n",
        "        total_memory=sum(stat.size for stat in snap.statistics('lineno'))\n",
        "        total_allocated_memory.append(format_memory(total_memory))\n",
        "        # Calculate the average allocated memory\n",
        "        num_snapshots = len(snap.statistics('lineno'))\n",
        "        average_allocated_memory.append(format_memory(total_memory / num_snapshots))\n",
        "        y_pred = hyper_model.predict(X_test_ML)\n",
        "        testing_accuracy.append(accuracy_score(y_test_full_ML, y_pred))\n",
        "        precision_value, recall_value, f1_score_value, support_value = sklearn.metrics.precision_recall_fscore_support(y_test_full_ML , y_pred, average= 'weighted' )\n",
        "        precision_list.append(precision_value)\n",
        "        recall_list.append(recall_value)\n",
        "        f1_score_list.append(f1_score_value)\n",
        "        models_size.append(format_memory(calculate_ML_size(hyper_model, \"model(\" + str(mean_score) + \")\")))\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    return [params_all,testing_accuracy,precision_list,recall_list,f1_score_list, models_size, execution_time_list,total_allocated_memory,average_allocated_memory], best_params ,mean_training_score_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC_E7_A_qcs4"
      },
      "outputs": [],
      "source": [
        "def evaluate_NN_models(model_list):\n",
        "  loss, accuracy , y_pred ,precision, recall ,f1_score ,support ,confusion_matrix_list = [], [], [], [], [], [], [], []\n",
        "  for model in model_list:\n",
        "    loss_value,accuracy_value=model.evaluate(X_test, y_test)\n",
        "    loss.append(loss_value)\n",
        "    accuracy.append(accuracy_value)\n",
        "    y_pred_value=np.argmax(model.predict(X_test), axis = 1)\n",
        "    y_pred.append(y_pred_value)\n",
        "    precision_value, recall_value, f1_score_value, support_value = sklearn.metrics.precision_recall_fscore_support(y_test , y_pred_value, average= 'weighted' )\n",
        "    precision.append(precision_value)\n",
        "    recall.append(recall_value)\n",
        "    f1_score.append(f1_score_value)\n",
        "    support.append(support_value)\n",
        "    confusion_matrix_value=confusion_matrix(y_test, y_pred_value)\n",
        "    confusion_matrix_list.append(confusion_matrix_value)\n",
        "  return [accuracy ,precision, recall ,f1_score],confusion_matrix_list,y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9geD5BAKJUg"
      },
      "outputs": [],
      "source": [
        "def plot_model_performace_accuracy(history):\n",
        "  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
        "  ax1.plot(history[0].history['accuracy'], 'g', label='Training Accuracy')\n",
        "  ax1.plot(history[0].history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "  ax1.set_title('training and validation')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('accuracy')\n",
        "  ax1.set_ylim(0.1, 1.01)\n",
        "  ax1.grid(True)\n",
        "  ax1.legend()\n",
        "  ax2.plot(history[1].history['accuracy'], 'g', label='Training Accuracy')\n",
        "  ax2.plot(history[1].history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "  ax2.set_title('training and validation')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.set_ylim(0.1, 1.01)\n",
        "  ax2.grid(True)\n",
        "  ax2.legend()\n",
        "  ax3.plot(history[2].history['accuracy'], 'g', label='Training Accuracy')\n",
        "  ax3.plot(history[2].history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "  ax3.set_title('training and validation')\n",
        "  ax3.set_xlabel('epoch')\n",
        "  ax3.set_ylabel('accuracy')\n",
        "  ax3.set_ylim(0.1, 1.01)\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTVrOjZnYxzq"
      },
      "outputs": [],
      "source": [
        "def plot_model_performance(history,number_of_epochs):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['loss'], 'g', label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'], color='orange', label='Validation Loss')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-9-qnH9Q_nR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(ax, conf_matrix, title, cmap):\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=cmap, cbar=False, ax=ax)\n",
        "    ax.set_title(title)\n",
        "\n",
        "def draw_confusion_matrix(matrix,name):\n",
        "  colormap=[\"Blues\",\"Greens\",\"Oranges\"]\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "  for i in range(len(matrix)):\n",
        "    plot_confusion_matrix(axes[i], matrix[i], \"Confusion Matrix  \"+name+ str(i+1), colormap[i])\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF_BtmSWi9Ky"
      },
      "outputs": [],
      "source": [
        "#### function for plotting tables\n",
        "from tabulate import tabulate\n",
        "def print_table(data,headers):\n",
        "  table_data = list(zip(*data))\n",
        "  table = tabulate(table_data, headers=headers, tablefmt='grid')\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82pFChydzcPy"
      },
      "outputs": [],
      "source": [
        "#function to calculate the size of machine learning models\n",
        "import joblib\n",
        "import os\n",
        "def calculate_ML_size(model,file_name):\n",
        "  model_filename = \"/content/\"+file_name+\".joblib\"\n",
        "  joblib.dump(model, model_filename)\n",
        "  file_size = os.path.getsize(model_filename)\n",
        "  return file_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLjH4-0ftyDD"
      },
      "outputs": [],
      "source": [
        "def convert_params_to_list(params_all):\n",
        "  all_keys = set()\n",
        "  for d in params_all:\n",
        "      all_keys.update(d.keys())\n",
        "\n",
        "  data_values = [[d.get(key, None) for d in params_all] for key in all_keys]\n",
        "  return data_values,all_keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwHHi40t55Z2"
      },
      "outputs": [],
      "source": [
        "def format_memory(memory_bytes):\n",
        "    if memory_bytes < 1024:\n",
        "        return f\"{memory_bytes} B\"\n",
        "    elif memory_bytes < 1024 * 1024:\n",
        "        return f\"{memory_bytes / 1024:.2f} KB\"\n",
        "    elif memory_bytes < 1024 * 1024 * 1024:\n",
        "        return f\"{memory_bytes / (1024 * 1024):.2f} MB\"\n",
        "    else:\n",
        "        return f\"{memory_bytes / (1024 * 1024 * 1024):.2f} GB\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HZGKYdNZNn4"
      },
      "source": [
        "# **Linear Classifier (Baseline)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKqtSMxcZui8"
      },
      "outputs": [],
      "source": [
        "# X_train_full_ML, X_test_ML, y_train_full_ML, y_test_full_ML = X[:train_size], X[train_size:], y[:train_size], y[train_size:]\n",
        "X_train_ML = np.array([np.array(x_train).reshape(-1) for x_train in X_train_full])\n",
        "X_test_ML = np.array([np.array(x_test).reshape(-1) for x_test in X_test])\n",
        "\n",
        "print('Shape:', X_train_ML.shape)\n",
        "print('Type:', X_train_ML.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSoKU5rLZV0Y"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "models_info_linear,best_params_linear,mean_training_score_all_linear = ML_hyperparameters_study(SGDClassifier(),param_grid, X_train_ML, X_test_ML, y_train_full, y_test,random=True)\n",
        "headers_linear=list(param_grid.keys())\n",
        "\n",
        "#### visulaize all hyperparameters with acuuracy and model size in one table\n",
        "\n",
        "headers_linear=['models','hyperparameters',' accuracy ','precision','recall','f1_score','model size','Runtime','total allocated memory','average allocated memory']\n",
        "models_name=[]\n",
        "for i in range(1, len(param_grid['alpha'])+1):\n",
        "  models_name.append(\"Linear model \" + str(i))\n",
        "data_linear=[models_name]\n",
        "data_linear.extend(models_info_linear)\n",
        "print_table(data_linear,headers_linear)\n",
        "print(\"best hyperparameter : \", best_params_linear)\n",
        "linear_classifier_accuracy=models_info_linear[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0abDXWnaomn"
      },
      "source": [
        "# **Decision Tree ( Random Forest Classifier)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHidNlrdavsA"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50],\n",
        "    'criterion': ['gini'],\n",
        "    'max_depth': [None, 5, 10, 20, 30]\n",
        "}\n",
        "\n",
        "models_info_DT,best_params_DT,mean_training_score_all_DT  = ML_hyperparameters_study(RandomForestClassifier(), param_grid, X_train_ML, X_test_ML, y_train_full, y_test,random=True)\n",
        "\n",
        "headers_DT=['models','hyperparameters',' accuracy ','precision','recall','f1_score','model size','Runtime','total allocated memory','average allocated memory']\n",
        "models_name=[]\n",
        "for i in range(1, 6):\n",
        "  models_name.append(\"RF model \" + str(i))\n",
        "data_DT=[models_name]\n",
        "data_DT.extend(models_info_DT)\n",
        "print_table(data_DT,headers_DT)\n",
        "print(\"best hyperparameter : \", best_params_DT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_sElX_29SoE"
      },
      "source": [
        "# **KNN Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdYEQGQh9SoJ"
      },
      "outputs": [],
      "source": [
        "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
        "\n",
        "models_info_KNN,best_params_KNN,mean_training_score_all_KNN = ML_hyperparameters_study(KNeighborsClassifier(),param_grid,X_train_ML, X_test_ML, y_train_full, y_test,random=False)\n",
        "\n",
        "\n",
        "#### visulaize all hyperparameters with acuuracy and model size in one table\n",
        "\n",
        "headers_KNN=['models','hyperparameters',' accuracy ','precision','recall','f1_score','model size','Runtime','total allocated memory','average allocated memory']\n",
        "models_name=[]\n",
        "for i in range(1, 7):\n",
        "  models_name.append(\"KNN model \" + str(i))\n",
        "data_KNN=[models_name]\n",
        "data_KNN.extend(models_info_KNN)\n",
        "print_table(data_KNN,headers_KNN)\n",
        "print(\"best hyperparameter : \", best_params_KNN)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljcvgMjlivyr"
      },
      "source": [
        "# **Fully connected NN (MLP)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix-RR64vizZ7"
      },
      "outputs": [],
      "source": [
        "def build_model_fc(number_of_hidden_layers, number_of_units, learning_rate=0.0001):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(height, width, number_of_channels)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    for i in range(number_of_hidden_layers):\n",
        "      model.add(tf.keras.layers.Dense( number_of_units[i], activation='relu'))\n",
        "      model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "    model.add(tf.keras.layers.Dense(4,activation='softmax'))\n",
        "\n",
        "    # Create an optimizer with the specified learning rate\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    # Compile the model with the hyperparameters\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_train,batch_size=batch_size, epochs=100, validation_data=(X_valid, y_valid))\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx4cC7F1XlKt"
      },
      "source": [
        "## Creating grid of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzhIJH4iXt0h"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def generate_reverse_sorted_powers_of_2(l, a, b):\n",
        "    # Calculate the minimum and maximum powers of 2 within the interval\n",
        "    min_power = np.ceil(np.log2(a))\n",
        "    max_power = np.floor(np.log2(b))\n",
        "\n",
        "    # Generate l random powers of 2 within the [min_power, max_power] range\n",
        "    powers = np.random.randint(min_power, max_power + 1, size=l)\n",
        "    powers_of_2 = 2 ** powers\n",
        "\n",
        "    # Sort the array in reverse order\n",
        "    reverse_sorted_powers_of_2 = np.sort(powers_of_2)[::-1]\n",
        "\n",
        "    return reverse_sorted_powers_of_2\n",
        "\n",
        "min_num_hidden_layers = 1  # Minimum number of hidden layers\n",
        "max_num_hidden_layers = 3  # Maximum number of hidden layers\n",
        "min_length = 32  # Minimum length of each hidden layer\n",
        "max_length = 256  # Maximum length of each hidden layer\n",
        "num_hidden_layers=[]\n",
        "hidden_layer_lengths = []\n",
        "num_layers = random.randint(min_num_hidden_layers, max_num_hidden_layers)\n",
        "number_of_models = 1\n",
        "for _ in range(number_of_models):\n",
        "    num_layers = random.randint(min_num_hidden_layers, max_num_hidden_layers)\n",
        "    num_hidden_layers.append(num_layers)\n",
        "    # Generate a list of random powers of 2 between min_length and max_length and sort them in descending order\n",
        "    # layer_lengths = sorted([random.randint(min_length, max_length) for _ in range(num_layers)], reverse=True)\n",
        "    # hidden_layer_lengths.append(layer_lengths)\n",
        "    hidden_layer_lengths.append(generate_reverse_sorted_powers_of_2(num_layers, min_length, max_length))\n",
        "\n",
        "for i in range(len(num_hidden_layers)):\n",
        "  print(f\"hidden layer :{num_hidden_layers[i]} , units: {hidden_layer_lengths[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAyYZPImu9hv"
      },
      "source": [
        "## In this section we will **build** and **train** Ten different MLP models each with different hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R2CeNN_YIka"
      },
      "outputs": [],
      "source": [
        "models_list_MLP=[]\n",
        "results_MLP=[]\n",
        "# num_hidden_layers=[1,2,3]\n",
        "# hidden_layer_lengths=[[512],[512,246],[512,246,128]]\n",
        "for i in range(len(num_hidden_layers)):\n",
        "  model,results=build_model_fc(num_hidden_layers[i],hidden_layer_lengths[i])\n",
        "  models_list_MLP.append(model)\n",
        "  results_MLP.append(results)\n",
        "  plot_model_performance(results,epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiehAoNJYxcJ"
      },
      "source": [
        "### Choose the best three MLP models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlNLyeSxY445"
      },
      "outputs": [],
      "source": [
        "result_all_models_FC,confusion_matrix_FC,predicitions_FC=evaluate_NN_models(models_list_MLP)\n",
        "def find_top_three_indexes(lst):\n",
        "    arr = np.array(lst)\n",
        "    top_indexes = arr.argsort()[-3:][::-1]\n",
        "    return top_indexes\n",
        "\n",
        "# Example usage:\n",
        "top_three_indexes = find_top_three_indexes(result_all_models_FC[0])\n",
        "print(\"Indexes of the top three values:\", top_three_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgH5T3UXvH6C"
      },
      "source": [
        "## Let's train the three models with the entire training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgpLl9FwsKZY"
      },
      "outputs": [],
      "source": [
        "MLP_best_models=[models_list_MLP[top_three_indexes[0]],models_list_MLP[top_three_indexes[1]],models_list_MLP[top_three_indexes[2]]]\n",
        "model1=MLP_best_models[0]\n",
        "model2=MLP_best_models[1]\n",
        "model3=MLP_best_models[2]\n",
        "results_total_train1 = model1.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n",
        "results_total_train2 = model2.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n",
        "results_total_train3 = model3.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI8N8lzbsLDI"
      },
      "outputs": [],
      "source": [
        "models_list_FC = []\n",
        "models_list_FC.append(model1)\n",
        "models_list_FC.append(model2)\n",
        "models_list_FC.append(model3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnKNnhz8rElV"
      },
      "outputs": [],
      "source": [
        "plot_model_performace_accuracy([results_MLP[top_three_indexes[0]],results_MLP[top_three_indexes[0]],results_MLP[top_three_indexes[0]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyXelBx3vL5u"
      },
      "source": [
        "## Evaluate the best three MLP models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zkgO5oTss-Q"
      },
      "outputs": [],
      "source": [
        "result_all_models_FC,confusion_matrix_FC,predicitions_FC=evaluate_NN_models(MLP_best_models)\n",
        "\n",
        "## create a table with all models results\n",
        "headers=['models','hyperparameter','accuracy','precision','recall','f1_score']\n",
        "\n",
        "hyperparameters_values=[]\n",
        "models=[]\n",
        "for i in range(len(top_three_indexes)):\n",
        "  hyperparameters_values.append(f\"{num_hidden_layers[top_three_indexes[i]]},{hidden_layer_lengths[top_three_indexes[i]]}\")\n",
        "  models.append(f\"MLP Model{i}\")\n",
        "data_normal_FC=[models]\n",
        "data_normal_FC.append(hyperparameters_values)\n",
        "data_normal_FC.extend(result_all_models_FC)\n",
        "print_table(data_normal_FC,headers)\n",
        "MLP_classifier_accuracy=result_all_models_FC[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81AM5PEcuou1"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(confusion_matrix_FC,\"MLP  model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHN6N68et-_P"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knA-lZadHHEv"
      },
      "outputs": [],
      "source": [
        "def build_model(hp,kernel_size=3):\n",
        "\n",
        "    # # Tune the learning rate for the optimizer\n",
        "    # hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    # # Tune the optimizer\n",
        "    # hp_optimizer = hp.Choice('optimizer', values=['adam'])\n",
        "    # # Tune the number of filters in the Conv2D layer\n",
        "    # hp_filters = hp.Int('filters', min_value=16, max_value=128, step=16)\n",
        "    # #tune the dropout values\n",
        "    # dropout_rate = hp.Choice('dropout', values=[0.5])\n",
        "    # #tuning weights initialization\n",
        "    # kernel_initializer = hp.Choice('kernel_initializer', values=['glorot_uniform'])\n",
        "    filters = hp[0]\n",
        "    neurons = hp[1]\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(height, width, number_of_channels)))\n",
        "    model.add(tf.keras.layers.Conv2D(filters = filters , kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "    model.add(tf.keras.layers.Conv2D(filters = filters/2 , kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(4))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "     # Compile the model with the hyperparameters\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'],)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyKybPUZG-RV"
      },
      "source": [
        "## Let's observe the most performing models and identify their hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZxoLDHz1HIr"
      },
      "outputs": [],
      "source": [
        "# Let's use a Bayesian approach to conduct the search.\n",
        "tuner = BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    #executions_per_trial=2,\n",
        "    directory='tuner_single_dense',\n",
        "    project_name='training_tuner_single_dense1'\n",
        ")\n",
        "\n",
        "#Let's start training models with different hyperparameters.\n",
        "tuner.search(X_train, y_train, epochs=75,batch_size=batch_size, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxJO0iYoHi9U"
      },
      "outputs": [],
      "source": [
        "num_trials = 9\n",
        "best_hps2 = tuner.get_best_hyperparameters(num_trials=num_trials)\n",
        "\n",
        "for idx, hyperparameters in enumerate(best_hps2):\n",
        "    print(f\"Set {idx + 1}: {hyperparameters.values}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYY9Ke1lIS-Y"
      },
      "outputs": [],
      "source": [
        "best_hyperparameter_CNN=[best_hps2[0],best_hps2[1],best_hps2[2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL1DrH7wjPfC"
      },
      "source": [
        "## Let's compare the accuracy trend on the training set and the validation set  for the 3 models with different hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdI_yVdlHsYu"
      },
      "outputs": [],
      "source": [
        "# Build the model with the best hp.\n",
        "model4,results4=NN_hyperparameter_fit((128, 256), \"CNN\")\n",
        "print(max(results4.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXnpHDyNJFLo"
      },
      "outputs": [],
      "source": [
        "# Build the model with the second best hp.\n",
        "model5,results5=NN_hyperparameter_fit((128, 128),\"CNN\")\n",
        "print(max(results5.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29nxon6fJnUT"
      },
      "outputs": [],
      "source": [
        "# Build the model with the best hp.\n",
        "model6,results6=NN_hyperparameter_fit((64, 128),\"CNN\")\n",
        "print(max(results6.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5VMP0aGr3QE"
      },
      "outputs": [],
      "source": [
        "plot_model_performace_accuracy([results4,results5,results6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaqmNKfujPfF"
      },
      "source": [
        "## Let's train the three models with the entire training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOyltvFRLzZy"
      },
      "outputs": [],
      "source": [
        "results_total_train4 = model4.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n",
        "results_total_train5 = model5.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n",
        "results_total_train6 = model6.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ylKHm65ayl"
      },
      "source": [
        "Adding all models in a list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX0fxFp75eHl"
      },
      "outputs": [],
      "source": [
        "models_list_CNN = []\n",
        "models_list_CNN.append(model4)\n",
        "models_list_CNN.append(model5)\n",
        "models_list_CNN.append(model6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF562MkZjPfG"
      },
      "source": [
        "## Evaluate the CNN models on test set\n",
        "Evaluate All models and print out a table with all parameters (model , hyperparameter, accyracy, precision, recall, f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTipflbguwdp"
      },
      "outputs": [],
      "source": [
        "result_all_models_CNN,confusion_matrix_CNN,predicitions=evaluate_NN_models(models_list_CNN)\n",
        "## create a table with all models results\n",
        "headers=['models','accuracy','precision','recall','f1_score']\n",
        "data_normal_CNN=[['CNN model 1',' CNN model 2', 'CNN model 3']]\n",
        "\n",
        "hyperparameters_values=[]\n",
        "# for idx, hyperparameters in enumerate(best_hyperparameter_CNN):\n",
        "#   hyperparameters_values.append(hyperparameters.values)\n",
        "# data_normal_CNN.append(hyperparameters_values)\n",
        "data_normal_CNN.extend(result_all_models_CNN)\n",
        "print_table(data_normal_CNN,headers)\n",
        "CNN_classifier_accuracy=result_all_models_CNN[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkb3ECFBadPY"
      },
      "source": [
        "Draw confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2laHmAfCafQm"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(confusion_matrix_CNN,\"CNN model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4dgcL2Xd8Bx"
      },
      "source": [
        "# **Deeper CNN (DCNN)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl1zAgVepvHl"
      },
      "outputs": [],
      "source": [
        "### number_of_convolutional : the number of convolutional layer\n",
        "### kernal_size : a list of kernal sizes for each convolutional layer repespectively\n",
        "def build_model_DCC(hp,number_of_convolutional=2,kernal_size=[5,5]):\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2,1e-3,1e-4])\n",
        "    # Tune the optimizer\n",
        "    hp_optimizer = hp.Choice('optimizer', values=['adam'])\n",
        "    # Tune the number of filters in the Conv2D layer\n",
        "    hp_filters = hp.Int('filters', min_value=16, max_value=128, step=16)\n",
        "    #tune the dropout values\n",
        "    dropout_rate = hp.Choice('dropout', values=[0.3,0.5])\n",
        "    #tuning weights initialization\n",
        "    kernel_initializer = hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal', 'lecun_normal'])\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n",
        "\n",
        "    for i in range(number_of_convolutional - 1):\n",
        "      model.add(tf.keras.layers.Conv2D(filters = hp_filters , kernel_size=(kernal_size[i], kernal_size[i]), activation='relu',padding='same', kernel_initializer=kernel_initializer))\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "      model.add(tf.keras.layers.Dropout(rate = dropout_rate))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters = hp_filters , kernel_size=(kernal_size[len(kernal_size)-1], kernal_size[len(kernal_size)-1]), activation='relu',padding='same', kernel_initializer=kernel_initializer))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate = dropout_rate))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(10, kernel_initializer=kernel_initializer))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    # Compile the model with the hyperparameters\n",
        "    model.compile(optimizer=hp_optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55wJBmnY6gMb"
      },
      "source": [
        "## Let's observe the most performing models and identify their hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IlDaedo6lwr"
      },
      "outputs": [],
      "source": [
        "# Let's use a Bayesian approach to conduct the search.\n",
        "tuner = BayesianOptimization(\n",
        "    build_model_DCC,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    #executions_per_trial=2,\n",
        "    directory='tuner_single_dense3',\n",
        "    project_name='training_tuner_single_dense16'\n",
        ")\n",
        "\n",
        "#Let's start training models with different hyperparameters.\n",
        "tuner.search(X_train, y_train, epochs=75,batch_size=batch_size, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trssd2pSyOUT"
      },
      "outputs": [],
      "source": [
        "num_trials = 10\n",
        "best_hps_DCNN = tuner.get_best_hyperparameters(num_trials=num_trials)\n",
        "for idx, hyperparameters in enumerate(best_hps_DCNN):\n",
        "    print(f\"Set {idx + 1}: {hyperparameters.values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHg-f69aIcNX"
      },
      "outputs": [],
      "source": [
        "best_hyperparameter_DCNN=[best_hps_DCNN[0],best_hps_DCNN[3],best_hps_DCNN[4]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfPtfsRjyyTf"
      },
      "source": [
        "## Train three models with the three best hyperparameters and study the performance of the model with validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rITqbBjgycvC"
      },
      "outputs": [],
      "source": [
        "model7,results7=NN_hyperparameter_fit(best_hyperparameter_DCNN[0],\"DCNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpLrskL5yp1d"
      },
      "outputs": [],
      "source": [
        "model8,results8=NN_hyperparameter_fit(best_hyperparameter_DCNN[1],\"DCNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2dFvtJMyp93"
      },
      "outputs": [],
      "source": [
        "model9,results9=NN_hyperparameter_fit(best_hyperparameter_DCNN[2],\"DCNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDGmglKZzCOq"
      },
      "outputs": [],
      "source": [
        "plot_model_performace_accuracy([results7,results8,results9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT2l5Hpcy9aD"
      },
      "source": [
        "## train the model on all the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmXW-fQUzA0j"
      },
      "outputs": [],
      "source": [
        "results_total_train7 = model7.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n",
        "results_total_train8 = model8.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n",
        "results_total_train9 = model9.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlZ0S2HrzhPR"
      },
      "outputs": [],
      "source": [
        "models_list_DCNN = []\n",
        "models_list_DCNN.append(model7)\n",
        "models_list_DCNN.append(model8)\n",
        "models_list_DCNN.append(model9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bXDmagDzvnu"
      },
      "source": [
        "## Evaluate All models and print out a table with all parameters (model , hyperparameter, accyracy, precision, recall, f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEieZUhFzwT0"
      },
      "outputs": [],
      "source": [
        "result_all_models_DCNN,confusion_matrix_DCNN,predicitions=evaluate_NN_models(models_list_DCNN)\n",
        "## create a table with all models results\n",
        "headers=['models','hyperparameter','accuracy','precision','recall','f1_score']\n",
        "data_normal_DCNN=[['DCNN model 1',' DCNN model 2', 'DCNN model 3']]\n",
        "\n",
        "hyperparameters_values=[]\n",
        "for idx, hyperparameters in enumerate(best_hyperparameter_DCNN):\n",
        "  hyperparameters_values.append(hyperparameters.values)\n",
        "data_normal_DCNN.append(hyperparameters_values)\n",
        "data_normal_DCNN.extend(result_all_models_DCNN)\n",
        "print_table(data_normal_DCNN,headers)\n",
        "DCNN_classifier_accuracy=result_all_models_DCNN[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33BXAYYZ0P0S"
      },
      "source": [
        "Draw confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMuVC7UJ0RuW"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(confusion_matrix_DCNN,\"DCNN model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUU_a3XeqxMq"
      },
      "source": [
        "\n",
        "# **TensorFlow Lite model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAK7VfJsbGfQ"
      },
      "source": [
        "## Functions to evaluate and print analysis for  tf lite / quantized models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7SYQ3xYqxMr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate(model_file, X, y, categoricalAccuarcy):\n",
        "    if(categoricalAccuarcy):\n",
        "      accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    else:\n",
        "      accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path = model_file)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()[0]\n",
        "    output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "    y_preds = []\n",
        "    y_real = []\n",
        "\n",
        "    for x, y_true in zip(X,y):\n",
        "        if input_details['dtype'] == np.uint8:\n",
        "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "            x = x / input_scale + input_zero_point\n",
        "        x = np.expand_dims(x, axis=0).astype(input_details[\"dtype\"])\n",
        "        interpreter.set_tensor(input_details[\"index\"], x)\n",
        "        interpreter.invoke()\n",
        "        y_pred = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "        accuracy.update_state(y_true, y_pred)\n",
        "         # Collect the predicted labels\n",
        "        if(categoricalAccuarcy):\n",
        "            y_preds.append(np.argmax(y_pred))\n",
        "        else:\n",
        "            y_preds.append(np.round(y_pred[0]))\n",
        "\n",
        "        y_real.append(y_true)\n",
        "    return accuracy.result(), y_preds, y_real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AwkNvbTqxMr"
      },
      "outputs": [],
      "source": [
        "def evaluate_tflite_quantized_models(models_list,base_filename_model,models_files,full=False):\n",
        "  tflite_model_accuracy,tflite_model_predicitons,y_true,precisions_tf_lite_model,recalls_tf_lite_model,f1_scores_tf_lite_model,confusion_tflite_matrix_list = [], [], [] ,[],[], [], []\n",
        "  for i in range(len(models_list)):\n",
        "    path = base_filename_model + '/' + models_files[i].name\n",
        "    print(\"path\",path)\n",
        "    accuracy, y_pred, y_real = evaluate(path, X_test, y_test, True)\n",
        "    tflite_model_accuracy.append(accuracy.numpy())\n",
        "    tflite_model_predicitons.append(y_pred)\n",
        "    y_true.append(y_real)\n",
        "    precision_value, recall_value, f1_score_value, support_value = sklearn.metrics.precision_recall_fscore_support(y_real , y_pred, average= 'weighted' )\n",
        "    precisions_tf_lite_model.append(precision_value)\n",
        "    recalls_tf_lite_model.append(recall_value)\n",
        "    f1_scores_tf_lite_model.append(f1_score_value)\n",
        "    confusion_matrix_value=confusion_matrix(y_test, y_pred)\n",
        "    confusion_tflite_matrix_list.append(confusion_matrix_value)\n",
        "  return [tflite_model_accuracy,precisions_tf_lite_model,recalls_tf_lite_model,f1_scores_tf_lite_model],confusion_tflite_matrix_list,tflite_model_predicitons\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a-Z7foywbsu"
      },
      "source": [
        "## Converting all models to tflite model using tensorflow lite converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVC6TsGTt5ku"
      },
      "outputs": [],
      "source": [
        "models_list=[model1,model2,model3,model4,model5,model6]\n",
        "#without the DCNN models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7cNq4bhqxMq"
      },
      "outputs": [],
      "source": [
        "tflite_models = []\n",
        "for index in range(len(models_list)):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[index])\n",
        "  tflite_models.append(converter.convert())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeAumtFjqxMq"
      },
      "source": [
        "## It's now a TensorFlow Lite model, but it's still using 32-bit float values for all parameter data. We can store the models in a file in order to estimate its size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN1FkWBkqxMq"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import os\n",
        "tflite_models_dir = pathlib.Path(\"./\")\n",
        "base_filename_model_tflite = 'tflite_model'\n",
        "path = tflite_models_dir/base_filename_model_tflite\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "tflite_model_files = []\n",
        "tflite_model_size = []\n",
        "\n",
        "for i in range(1, len(models_list) +1):\n",
        "  filename = f\"{base_filename_model_tflite}_{i}.tflite\"\n",
        "  tflite_model_files.append(path/filename)\n",
        "  tflite_model_files[i-1].write_bytes(tflite_models[i-1])\n",
        "  tflite_model_size.append(os.path.getsize(tflite_model_files[i -1]) / float(2**10))\n",
        "  print(\"TFlite model in KB:\", tflite_model_size[i-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF5adl6njPfJ"
      },
      "source": [
        "## Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo3mhz-OZGfD"
      },
      "outputs": [],
      "source": [
        "tflite_all_results, confusion_tflite_all, tflite_predictions = evaluate_tflite_quantized_models(models_list,base_filename_model_tflite,tflite_model_files)\n",
        "## create a table with all tf lite models results\n",
        "headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n",
        "data_tflite=[['tflite MLP model 1','tflite MLP model 2', 'tflite MLP model 3',\n",
        "              'tflite CNN model 1','tflite CNN model 2', 'tflite CNN model 3',\n",
        "              'tflite DCNN model 1','tflite DCNN model 2', 'tflite DCNN model 3']]\n",
        "hyperparameters_values=[]\n",
        "\n",
        "for i in range(len(top_three_indexes)):\n",
        "  hyperparameters_values.append(f\"{num_hidden_layers[top_three_indexes[i]]},{hidden_layer_lengths[top_three_indexes[i]]}\")\n",
        "\n",
        "\n",
        "for idx, hyperparameters in enumerate(best_hyperparameter_CNN):\n",
        "  hyperparameters_values.append(hyperparameters.values)\n",
        "\n",
        "for idx, hyperparameters in enumerate(best_hyperparameter_DCNN):\n",
        "  hyperparameters_values.append(hyperparameters.values)\n",
        "\n",
        "data_tflite.append(hyperparameters_values)\n",
        "data_tflite.extend(tflite_all_results)\n",
        "data_tflite.append(tflite_model_size)\n",
        "print_table(data_tflite,headers)\n",
        "NN_model_sizes=tflite_model_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JRZqEpUqxMr"
      },
      "source": [
        "# **Post-training quantization**\n",
        "\n",
        "We can enable the default optimizations flag to quantize all fixed parameters (weights and biases) to 8-bit integers. Notice that scale and zero point for weights and bias can be calculated before the inference, becouse their ranges are already available. But how we can calculate scale and zero point for activations? We can use the **dynamic quantization**, in which scale and zero point for activations are calculated on-the-fly (online during inference). This means that the activations are always stored in float 32 and they are converted to integers while processing and back to floating point after the processing is done.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLvlcFezxB7z"
      },
      "source": [
        "## TFlite Dynamic Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvE7tJamqxMr"
      },
      "outputs": [],
      "source": [
        "tflite_dynamic_quantized_models = []\n",
        "\n",
        "for i in range (0 , len(models_list)):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[i])\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  tflite_dynamic_quantized_models.append(converter.convert())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfbztuEiqxMs"
      },
      "outputs": [],
      "source": [
        "tflite_dynamic_quantized_model_files = []\n",
        "tflite_dynamic_quantized_model_size = []\n",
        "\n",
        "base_filename_dynamic = 'tflite_dynamic_quantized_model'\n",
        "path = tflite_models_dir/base_filename_dynamic\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "for i in range (1, len(models_list) + 1):\n",
        "  file_name =  f\"{base_filename_dynamic}_{i}.tflite\"\n",
        "  tflite_dynamic_quantized_model_files.append(path/file_name)\n",
        "  tflite_dynamic_quantized_model_files[i-1].write_bytes(tflite_dynamic_quantized_models[i-1])\n",
        "  tflite_dynamic_quantized_model_size.append(os.path.getsize(tflite_dynamic_quantized_model_files[i - 1]) / float(2**10))\n",
        "  print(\"TFlite dynamic quantized model in KB:\", tflite_dynamic_quantized_model_size[i-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGcAO554criq"
      },
      "source": [
        "### Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model_dynamic_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3JMRv6MXD46"
      },
      "outputs": [],
      "source": [
        "dynamic_quantized_all_results, confusion_dynamic_quantized_all, dynamic_quantized_predictions = evaluate_tflite_quantized_models(models_list,base_filename_dynamic,tflite_dynamic_quantized_model_files)\n",
        "## create a table with all tf lite models results\n",
        "headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n",
        "data_dynamic_quantized=[['Dynamic quantized MLP model 1','Dynamic quantized MLP model 2', 'Dynamic quantized MLP model 3',\n",
        "                         'Dynamic quantized CNN model 1','Dynamic quantized CNN model 2', 'Dynamic quantized CNN model 3',\n",
        "                        'Dynamic quantized DCNN model 1','Dynamic quantized DCNN model 2', 'Dynamic quantized DCNN model 3']]\n",
        "data_dynamic_quantized.append(hyperparameters_values)\n",
        "data_dynamic_quantized.extend(dynamic_quantized_all_results)\n",
        "data_dynamic_quantized.append(tflite_dynamic_quantized_model_size)\n",
        "print_table(data_dynamic_quantized,headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnsT3qFDjPfP"
      },
      "source": [
        "## Static Quantization\n",
        "The model is now smaller with quantized weights with some decrease in the accuracy, but other variable data are still in float format. To quantize variable data (input/output and intermediates between layers), we can use **static quantization** to pre-computes scales and zero points also for all variable data in order to eliminate this overhead. However, we need some representative data in order to collect the distribution statistics for all the variable data and compute an estime of scales and zero points. The short-coming is that if the data is not representative, the scales and zero points computed might not reflect the true scenario during inference, and the inference accuracy will be harmed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnE_UlZkqxMt"
      },
      "outputs": [],
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
        "      input_value = tf.cast(input_value, tf.float32)\n",
        "      yield [input_value]\n",
        "\n",
        "tflite_static_quantized_models = []\n",
        "\n",
        "for i in range (0 , len(models_list)):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[i])\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.representative_dataset = representative_data_gen\n",
        "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "  # Convert the model to a quantized TFLite model\n",
        "  tflite_static_quantized_models.append(converter.convert())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXfL2hewqxMt"
      },
      "outputs": [],
      "source": [
        "tflite_static_quantized_model_files = []\n",
        "tflite_static_quantized_model_size = []\n",
        "\n",
        "base_filename_static = 'tflite_static_quantized_model'\n",
        "path = tflite_models_dir/base_filename_static\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "for i in range (1, len(models_list) + 1):\n",
        "  file_name =  f\"{base_filename_static}_{i}.tflite\"\n",
        "  tflite_static_quantized_model_files.append(path/file_name)\n",
        "  tflite_static_quantized_model_files[i - 1].write_bytes(tflite_static_quantized_models[i - 1])\n",
        "  tflite_static_quantized_model_size.append(os.path.getsize(tflite_static_quantized_model_files[i - 1]) / float(2**10))\n",
        "  print(\"TFlite static quantized model in KB:\", tflite_static_quantized_model_size[i-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx5wtz8xjPfQ"
      },
      "source": [
        "### Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model_static_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef3jL6hKqxMt"
      },
      "outputs": [],
      "source": [
        "static_quantized_all_results, confusion_static_quantized_all, static_quantized_predictions = evaluate_tflite_quantized_models(models_list,base_filename_static,tflite_static_quantized_model_files)\n",
        "## create a table with all tf lite models results\n",
        "headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n",
        "data_static_quantized=[['Static quantized MLP model 1','Static quantized MLP model 2', 'Static quantized MLP model 3',\n",
        "                        'Static quantized CNN model 1','Static quantized CNN model 2', 'Static quantized CNN model 3',\n",
        "                        'Static quantized DCNN model 1','Static quantized DCNN model 2', 'Static quantized DCNN model 3']]\n",
        "# data_static_quantized.append(hyperparameters_values)\n",
        "data_static_quantized.extend(static_quantized_all_results)\n",
        "data_static_quantized.append(tflite_static_quantized_model_size)\n",
        "print_table(data_static_quantized,headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3_niyOBqxMt"
      },
      "source": [
        "## Full static Quantization\n",
        "Now all weights and variable data are quantized. However, to maintain compatibility with applications that traditionally use float model, the TensorFlow Lite Converter leaves the model input and output tensors in float. This is good for compatibility, but it won't be compatible with devices that perform only integer-based operations. To ensure end-to-end integer-only model, we need to specify some parameters to the converter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRfn9vIMqxMu"
      },
      "outputs": [],
      "source": [
        "tflite_full_static_quantized_models = []\n",
        "\n",
        "for i in range(0, len(models_list)):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[i])\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.representative_dataset = representative_data_gen\n",
        "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "  converter.inference_input_type = tf.uint8\n",
        "  converter.inference_output_type = tf.uint8\n",
        "  tflite_full_static_quantized_models.append(converter.convert())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFtAoEXSqxMu"
      },
      "source": [
        "### The internal quantization remains the same as above, but we can see the input and output tensors are now integer format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iCvHPMMqxMu"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_content = tflite_full_static_quantized_models[0])\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLJ3UUXPqxMu"
      },
      "outputs": [],
      "source": [
        "tflite_full_static_quantized_model_files = []\n",
        "tflite_full_static_quantized_model_size = []\n",
        "\n",
        "base_filename_full_static = 'tflite_full_static_quantized_model'\n",
        "path = tflite_models_dir/base_filename_full_static\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "for i in range(1, len(models_list) + 1) :\n",
        "  file_name =  f\"{base_filename_full_static}_{i}.tflite\"\n",
        "  tflite_full_static_quantized_model_files.append(path/file_name)\n",
        "  tflite_full_static_quantized_model_files[i - 1].write_bytes(tflite_full_static_quantized_models[i - 1])\n",
        "  tflite_full_static_quantized_model_size.append(os.path.getsize(tflite_full_static_quantized_model_files[i - 1]) / float(2**10))\n",
        "  print(\"TFlite full static quantized model in KB:\", tflite_full_static_quantized_model_size[i-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyYekcEYjPfT"
      },
      "source": [
        "### Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model_full_static_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2KDJ1qtqxMu"
      },
      "outputs": [],
      "source": [
        "full_static_quantized_all_results, confusion_full_static_quantized_all, full_static_quantized_predictions = evaluate_tflite_quantized_models(models_list,base_filename_full_static,tflite_full_static_quantized_model_files,full=True)\n",
        "## create a table with all tf lite models results\n",
        "headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n",
        "data_full_static_quantized=[['Full static quantized MLP model 1','full static quantized MLP model 2', 'full static quantized MLP model 3',\n",
        "                             'Full static quantized CNN model 1','full static quantized CNN model 2', 'full static quantized CNN model 3']]\n",
        "data_full_static_quantized.append(hyperparameters_values)\n",
        "data_full_static_quantized.extend(full_static_quantized_all_results)\n",
        "data_full_static_quantized.append(tflite_full_static_quantized_model_size)\n",
        "print_table(data_full_static_quantized,headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmCqpGjTf-DT"
      },
      "source": [
        "# **Best models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jla4e1q_2qv6"
      },
      "outputs": [],
      "source": [
        "linear_index=linear_classifier_accuracy.index(max(linear_classifier_accuracy))\n",
        "MLP_index=MLP_classifier_accuracy.index(max(MLP_classifier_accuracy))\n",
        "CNN_index=CNN_classifier_accuracy.index(max(CNN_classifier_accuracy))\n",
        "# uncomment the lines below if DCNN is included\n",
        "# DCNN_index=DCNN_classifier_accuracy.index(max(DCNN_classifier_accuracy))\n",
        "# print(linear_index,MLP_index,CNN_index,DCNN_index)\n",
        "\n",
        "\n",
        "# tflite_modelfiles_best=[tflite_model_files[MLP_index],tflite_model_files[CNN_index + 3],tflite_model_files[DCNN_index + 6]]\n",
        "# dynamic_modelfiles_best=[tflite_dynamic_quantized_model_files[MLP_index],tflite_dynamic_quantized_model_files[CNN_index + 3],tflite_dynamic_quantized_model_files[DCNN_index + 6]]\n",
        "# static_modelfiles_best=[tflite_static_quantized_model_files[MLP_index],tflite_static_quantized_model_files[CNN_index + 3],tflite_static_quantized_model_files[DCNN_index + 6]]\n",
        "tflite_modelfiles_best=[tflite_model_files[MLP_index],tflite_model_files[CNN_index + 3]]\n",
        "dynamic_modelfiles_best=[tflite_dynamic_quantized_model_files[MLP_index],tflite_dynamic_quantized_model_files[CNN_index + 3]]\n",
        "static_modelfiles_best=[tflite_static_quantized_model_files[MLP_index],tflite_static_quantized_model_files[CNN_index + 3]]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU0BlqEQjPfU"
      },
      "source": [
        "# **Quantization Aware Training**\n",
        "Quantization introduces information loss and therefore the inference accuracy from the quantized integer models are inevitably lower than that from the floating point models. Such information loss is due to that the floating points after quantization and de-quantization is not exactly recoverable. The idea of quantization aware training is to ask the neural network to take the effect of such information loss into account during training. We can use the TensorFlow Model Optimization toolkit and passing in input the Keras model. What that API is doing is extending that network with the ability to mimic the quantized behavior that would be happening during the inference time, during the training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_80xQHD3rr8m"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-model-optimization==0.7.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBSLFU-3Kf3f"
      },
      "source": [
        "## Functions for building aware MLP, CNN and DCNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEDJvoWOqxMv"
      },
      "outputs": [],
      "source": [
        "def build_model_aware_CNN(quantizator,kernel_size=3):\n",
        "\n",
        "    filters = 64\n",
        "    neurons = 128\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(height, width, number_of_channels)))\n",
        "    model.add(tf.keras.layers.Conv2D(filters = filters , kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "    model.add(tf.keras.layers.Conv2D(filters = filters/2 , kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(4))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    quantization_aware_model = quantizator(model)\n",
        "     # Compile the model with the hyperparameters\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    quantization_aware_model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'],)\n",
        "\n",
        "    return quantization_aware_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7kxZ1mI9i9u"
      },
      "outputs": [],
      "source": [
        "def build_model_aware_fc(quantizator,number_of_hidden_layers=1,number_of_units=128):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(height, width, number_of_channels)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    for i in range(1,number_of_hidden_layers+1):\n",
        "      model.add(tf.keras.layers.Dense( number_of_units/i, activation='relu'))\n",
        "      model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "    model.add(tf.keras.layers.Dense(4,activation='softmax'))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    quantization_aware_model = quantizator(model)\n",
        "     # Compile the model with the hyperparameters\n",
        "    quantization_aware_model.compile(optimizer=\"adam\",\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'],)\n",
        "    return quantization_aware_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbK5vW3VA9FS"
      },
      "outputs": [],
      "source": [
        "def build_model_aware_DCNN(quantizator,number_of_convolutional=2,kernal_size=[3,3]):\n",
        "\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n",
        "    model.add(tf.keras.layers.Reshape(target_shape=(width, height, number_of_channels)))\n",
        "\n",
        "    for i in range(1,number_of_convolutional):\n",
        "      model.add(tf.keras.layers.Conv2D(128 , kernel_size=(kernal_size[i], kernal_size[i]), activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "      model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128 , kernel_size=(kernal_size[len(kernal_size)-1], kernal_size[len(kernal_size)-1]), activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128,activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "    quantization_aware_model = quantizator(model)\n",
        "    quantization_aware_model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'],)\n",
        "    quantization_aware_model.summary()\n",
        "    return quantization_aware_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl0benL7LYZI"
      },
      "source": [
        "## build models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_XJABxLzEaG"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "quantizator = tfmot.quantization.keras.quantize_model\n",
        "quantization_aware_model1=build_model_aware_fc(quantizator)\n",
        "quantization_aware_model2=build_model_aware_CNN(quantizator)\n",
        "# quantization_aware_model3=build_model_aware_DCNN(quantizator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ccqFczqxMv"
      },
      "source": [
        "## When we train the networks, it is implicitly learning to be resilient to the quantization error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL-MNu4OqxMv"
      },
      "outputs": [],
      "source": [
        "aware_results1 = quantization_aware_model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
        "aware_results2 = quantization_aware_model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
        "# aware_results3 = quantization_aware_model3.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu6zTcY_qxMw"
      },
      "outputs": [],
      "source": [
        "plot_model_performace_accuracy([aware_results1,aware_results2,aware_results3])\n",
        "plot_model_performace_accuracy([aware_results1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRs0p9y1A32P"
      },
      "outputs": [],
      "source": [
        "aware_model_list=[quantization_aware_model1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcylnWd8qxMw"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"./\")\n",
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
        "      input_value = tf.cast(input_value, tf.float32)\n",
        "      yield [input_value]\n",
        "\n",
        "tflite_aware_quantized_models = []\n",
        "for i in range(0, len(aware_model_list)):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(aware_model_list[i])\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.representative_dataset = representative_data_gen\n",
        "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "  converter.inference_input_type = tf.uint8\n",
        "  converter.inference_output_type = tf.uint8\n",
        "  tflite_aware_quantized_models.append(converter.convert())\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content = tflite_aware_quantized_models[0])\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "tflite_aware_quantized_model_files = []\n",
        "tflite_aware_quantized_model_size = []\n",
        "\n",
        "base_filename_aware = 'tflite_aware_quantized_model'\n",
        "path = tflite_models_dir/base_filename_aware\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "for i in range(1, len(aware_model_list) + 1) :\n",
        "  file_name =  f\"{base_filename_aware}_{i}.tflite\"\n",
        "  tflite_aware_quantized_model_files.append(path/file_name)\n",
        "  tflite_aware_quantized_model_files[i - 1].write_bytes(tflite_aware_quantized_models[i - 1])\n",
        "  tflite_aware_quantized_model_size.append(os.path.getsize(tflite_aware_quantized_model_files[i - 1]) / float(2**10))\n",
        "  print(\"TFlite aware quantized model in KB:\", tflite_aware_quantized_model_size[i-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouJIZDJRjPfW"
      },
      "source": [
        "## Calculate Accuracy, Precision, Recall, F1 Tf_lite_aware_quantized_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygt18mgzqxMw"
      },
      "outputs": [],
      "source": [
        "aware_quantized_all_results, confusion_aware_quantized_all, aware_quantized_predictions = evaluate_tflite_quantized_models(aware_model_list,base_filename_aware,tflite_aware_quantized_model_files,full=True)\n",
        "## create a table with all tf lite models results\n",
        "headers=['models','accuracy','precision','recall','f1_score','model size KB']\n",
        "data_aware_quantized=[['Aware quantized MLP model ','Aware quantized model CNN ', 'Aware quantized DCNN model ']]\n",
        "\n",
        "data_aware_quantized.extend(aware_quantized_all_results)\n",
        "data_aware_quantized.append(tflite_aware_quantized_model_size)\n",
        "print_table(data_aware_quantized,headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ffK-qn1EZE3"
      },
      "source": [
        "# **Benchmark Models with STM tools**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRTtfiySUQdH"
      },
      "outputs": [],
      "source": [
        "dynamic_modelfiles_best = []\n",
        "static_modelfiles_best = []\n",
        "tflite_aware_quantized_model_files = ['tflite_aware_quantized_model_1.tflite', 'tflite_aware_quantized_model_2.tflite']\n",
        "\n",
        "base_file_name_dq = '.'\n",
        "base_file_name_sq = '.'\n",
        "base_file_name_qa = './tflite_aware_quantized_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZrtTZTi01aq"
      },
      "outputs": [],
      "source": [
        "# download from github requirement.txt\n",
        "import requests\n",
        "\n",
        "github_file_url = 'https://github.com/STMicroelectronics/stm32ai-modelzoo/blob/main/requirements.txt'\n",
        "local_file_path = 'requirements.txt'\n",
        "\n",
        "response = requests.get(github_file_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    json_data = response.json()  # Converti la risposta in JSON\n",
        "    file_content = json_data['payload']['blob']['rawLines']  # Estrai il contenuto del file\n",
        "\n",
        "    with open(local_file_path, 'w') as file:\n",
        "        for line in file_content:\n",
        "            file.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQr7_l_YFXwE"
      },
      "outputs": [],
      "source": [
        "#install package defined in requirement.txt\n",
        "!pip install -q -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoSVfdhuEgGu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"STM32AI_USERNAME\"] = \"luca.lazzaroni@edu.unige.it\"\n",
        "os.environ[\"STM32AI_PASSWORD\"] = \"37K5m5L7P6PVfW!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB2Lz7IcKOfu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install pycurl seaborn numpy matplotlib\n",
        "!{sys.executable} -m pip install ipywidgets\n",
        "!{sys.executable} -m pip install gitdir\n",
        "!{sys.executable} -m pip install shutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kYxsji4L-No"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "# Get STM32Cube.AI Developer Cloud\n",
        "!gitdir https://github.com/STMicroelectronics/stm32ai-modelzoo/tree/main/common/stm32ai_dc\n",
        "\n",
        "# Reorganize local folders\n",
        "if os.path.exists('./stm32ai_dc'):\n",
        "    shutil.rmtree('./stm32ai_dc')\n",
        "shutil.move('./common/stm32ai_dc', './stm32ai_dc')\n",
        "shutil.rmtree('./common')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B10qsQH1MJC2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "\n",
        "sys.path.append(os.path.abspath('stm32ai'))\n",
        "os.environ['STATS_TYPE'] = 'jupyter_devcloud'\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('outputs', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQpJKoM-paeN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Append sys.path in order to add import folder for STM32AI\n",
        "dir_name = os.path.dirname('./')\n",
        "sys.path.insert(0, os.path.abspath(os.path.join(dir_name, '..')))\n",
        "sys.path.append(os.path.abspath('../../../common'))\n",
        "from stm32ai_dc import Stm32Ai, CloudBackend, CliParameters\n",
        "from stm32ai_dc.errors import ParameterError, BenchmarkServerError\n",
        "\n",
        "# Get username/password from environment\n",
        "username = os.environ.get('STM32AI_USERNAME', None)\n",
        "password = os.environ.get('STM32AI_PASSWORD', None)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Create STM32AI Class with Cloud Backend, given a username/password and a possible version\n",
        "# Version set to \"None\" will use the latest version available in Developer Cloud\n",
        "ai = Stm32Ai(CloudBackend(username, password, version=None))\n",
        "\n",
        "# List boards available for a benchmark in STM32Cube.AI Developer Cloud\n",
        "boards = ai.get_benchmark_boards()\n",
        "\n",
        "\n",
        "# Boards length should be greater than zero\n",
        "# A length equals to zero mean a current maintenance or a failure\n",
        "if len(boards) == 0:\n",
        "    print(\"No board detected remotely, can't start benchmark\")\n",
        "    sys.exit(0)\n",
        "\n",
        "boards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-X3Yp3epgXt"
      },
      "source": [
        "# **Benchmark models on STM boards**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ0WexL1aU0c"
      },
      "outputs": [],
      "source": [
        "#uploading models to ST\n",
        "def upload_model(number_of_models,base_file_name_model,model_file_names):\n",
        "\n",
        "  model_names=[]\n",
        "  for i in range(number_of_models):\n",
        "    path_model = base_file_name_model + '/' + model_file_names[i]\n",
        "    ai.upload_model(path_model)\n",
        "    model_names.append(model_file_names[i])\n",
        "  return model_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd0yH0VxbFlr"
      },
      "outputs": [],
      "source": [
        "#deleting model from ST\n",
        "def delete_model(number_of_models,model_names):\n",
        "  for i in range(number_of_models):\n",
        "    model_name=model_names[i]\n",
        "    ai.delete_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SXwGGe2bhtH"
      },
      "outputs": [],
      "source": [
        "### Analyze and benchmark models\n",
        "def analyze_benchmark_ST(board_name,model_name):\n",
        "  activation_size,weights_size,macc,rom_size,ram_size,execution_time=[], [], [], [], [], []\n",
        "  for i in range(len(model_name)):\n",
        "    analyzing=ai.analyze(CliParameters(model=model_name[i]))\n",
        "    print(analyzing)\n",
        "    activation_size.append(analyzing.activations_size)\n",
        "    weights_size.append(analyzing.weights)\n",
        "    macc.append(analyzing.macc)\n",
        "    rom_size.append(analyzing.rom_size)\n",
        "    ram_size.append(analyzing.ram_size)\n",
        "    benchamrking=ai.benchmark(CliParameters(model = model_name[i]), board_name)\n",
        "    print(benchamrking)\n",
        "    execution_time.append(benchamrking.graph['exec_time']['duration_ms'])\n",
        "  return [activation_size,weights_size,macc,rom_size,ram_size,execution_time]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VQHmRuJ4j5a"
      },
      "outputs": [],
      "source": [
        "##### benchmark and analyze models\n",
        "def process_models_st(models_number,base_file_name,models_name,model_type):\n",
        "  tflite_model_names=upload_model(models_number,base_file_name,models_name)\n",
        "  data_tflite_board1,data_tflite_board2,data_tflite_board3,data_tflite_board4=[],[],[],[]\n",
        "  print(\"models names\",tflite_model_names)\n",
        "\n",
        "  ######### benchmark and analyze dynamic quantized model with 'B_U585I_IOT02A' 4\n",
        "  B_U585I_IOT02A_tflite_models_results=analyze_benchmark_ST('B-U585I-IOT02A',tflite_model_names)\n",
        "  headers=[\"models\",\"activation_size\",\"weights_size\",\"macc\",\"rom_size\",\"ram_size\",\"execution_time\"]\n",
        "  data_tflite_board1=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n",
        "  data_tflite_board1.extend(B_U585I_IOT02A_tflite_models_results)\n",
        "\n",
        "  ######### benchmark and analyze dynamic quantized model with 'STM32F469I-DISCO' 0\n",
        "  STM32F469I_DISCO_tflite_models_results=analyze_benchmark_ST('STM32F469I-DISCO',tflite_model_names)\n",
        "  data_tflite_board2=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n",
        "  data_tflite_board2.extend(STM32F469I_DISCO_tflite_models_results)\n",
        "\n",
        "  ######### benchmark and analyze dynamic quantized model with  'STM32L4R9I-DISCO' 1\n",
        "  STM32L4R9I_DISCO_tflite_models_results=analyze_benchmark_ST('STM32L4R9I-DISCO',tflite_model_names)\n",
        "  data_tflite_board3=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n",
        "  data_tflite_board3.extend(STM32L4R9I_DISCO_tflite_models_results)\n",
        "\n",
        "  ######### benchmark and analyze dynamic quantized model with  'STM32H7B3I-DK' 2\n",
        "  STM32H7B3I_DK_tflite_models_results=analyze_benchmark_ST('STM32H7B3I-DK',tflite_model_names)\n",
        "  data_tflite_board4=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n",
        "  data_tflite_board4.extend(STM32H7B3I_DK_tflite_models_results)\n",
        "\n",
        "  delete_model(models_number,tflite_model_names)\n",
        "  print(\"B-U585I-IOT02A\")\n",
        "  print_table(data_tflite_board1,headers)\n",
        "  print(\"STM32F469I-DISCO\")\n",
        "  print_table(data_tflite_board2,headers)\n",
        "  print(\"STM32L4R9I-DISCO\")\n",
        "  print_table(data_tflite_board3,headers)\n",
        "  print(\"STM32H7B3I-D\")\n",
        "  print_table(data_tflite_board4,headers)\n",
        "  return B_U585I_IOT02A_tflite_models_results, STM32F469I_DISCO_tflite_models_results,STM32L4R9I_DISCO_tflite_models_results,STM32H7B3I_DK_tflite_models_results,data_tflite_board1,data_tflite_board2,data_tflite_board3,data_tflite_board4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG_uiA0gR8E9"
      },
      "source": [
        "## Analyze and Benchmark best models on STM boards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9JSxSC0djKe"
      },
      "outputs": [],
      "source": [
        "############# tflite model hardware analysis and benchmarking\n",
        "B_U585I_IOT02A_tflite_models_result, STM32F469I_DISCO_tflite_models_result,STM32L4R9I_DISCO_tflite_models_result,STM32H7B3I_DK_tflite_models_result,data_tflite_model_board1,data_tflite_model_board2,data_tflite_model_board3,data_tflite_model_board4=process_models_st(len(tflite_modelfiles_best),base_filename_model_tflite,tflite_modelfiles_best,\"tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHmwqkAa6Y2N"
      },
      "outputs": [],
      "source": [
        "############# dynamic quantized tflite model hardware analysis and benchmarking\n",
        "B_U585I_IOT02A_dynamic_quantized_tflite_models_result, STM32F469I_DISCO_dynamic_quantized_tflite_models_result,STM32L4R9I_DISCO_dynamic_quantized_tflite_models_result,STM32H7B3I_DK_dynamic_quantized_tflite_models_result,data_dynamic_model_board1,data_dynamic_model_board2,data_dynamic_model_board3,data_dynamic_model_board4=process_models_st(len(dynamic_modelfiles_best),base_filename_dynamic,dynamic_modelfiles_best,\"dynamic quantized tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf0Nzd2X6z6_"
      },
      "outputs": [],
      "source": [
        "############# static quantized tflite model hardware analysis and benchmarking\n",
        "B_U585I_IOT02A_static_quantized_tflite_models_result, STM32F469I_DISCO_static_quantized_tflite_models_result,STM32L4R9I_DISCO_static_quantized_tflite_models_result,STM32H7B3I_DK_static_quantized_tflite_models_result,data_static_model_board1,data_static_model_board2,data_static_model_board3,data_static_model_board4=process_models_st(len(static_modelfiles_best),base_filename_static,static_modelfiles_best,\"static quantized tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBXkRi-SHSr9"
      },
      "outputs": [],
      "source": [
        "############# aware quantized tflite model hardware analysis and benchmarking\n",
        "B_U585I_IOT02A_aware_quantized_tflite_models_result, STM32F469I_DISCO_aware_quantized_tflite_models_result,STM32L4R9I_DISCO_aware_quantized_tflite_models_result,STM32H7B3I_DK_aware_quantized_tflite_models_result,data_aware_model_board1,data_aware_board2,data_aware_model_board3,data_aware_model_board4=process_models_st(len(tflite_aware_quantized_model_files),base_filename_aware,tflite_aware_quantized_model_files,\"aware quantized tflite\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNKIOTHzp3dO"
      },
      "source": [
        "# **Generate C Code from your model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWLhuQPfqHoZ"
      },
      "outputs": [],
      "source": [
        "##### Generate C code for your model\n",
        "def generate_C_Code(models_number,base_file_name,models_name,model_type):\n",
        "  tflite_model_names=upload_model(models_number,base_file_name,models_name)\n",
        "  print(\"models names\",tflite_model_names)\n",
        "  for i in range(len(tflite_model_names)):\n",
        "    model_output=f\"./model_output {i}\"\n",
        "    res= ai.generate(CliParameters(model=tflite_model_names[i], output=model_output))\n",
        "    print(\"Result from local file:\", res, flush=True)\n",
        "  delete_model(models_number,tflite_model_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOthc6wNvPGI"
      },
      "outputs": [],
      "source": [
        "generate_C_Code(len(static_modelfiles_best),base_filename_static,static_modelfiles_best,\"static quantized tflite\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FZvDBg5SqxMY",
        "w2ou5uc7qxMe",
        "4HZGKYdNZNn4",
        "m0abDXWnaomn",
        "w_sElX_29SoE",
        "MHN6N68et-_P",
        "oyKybPUZG-RV",
        "J4dgcL2Xd8Bx",
        "55wJBmnY6gMb",
        "JfPtfsRjyyTf",
        "tT2l5Hpcy9aD",
        "6bXDmagDzvnu",
        "fAK7VfJsbGfQ",
        "V3_niyOBqxMt",
        "xFtAoEXSqxMu",
        "uyYekcEYjPfT",
        "ouJIZDJRjPfW",
        "3ffK-qn1EZE3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
