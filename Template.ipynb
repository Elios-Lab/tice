{"cells":[{"cell_type":"markdown","metadata":{"id":"yK-ONXiYqxMW"},"source":["# **Template Notebook**\n"]},{"cell_type":"markdown","metadata":{"id":"FZvDBg5SqxMY"},"source":["# **Download dataset:**\n","In this the section the user can download the dataset for analyzing and building TinML models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxF-e7i0XOC8"},"outputs":[],"source":["### download the image dataset from a link or using file system"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCLHFd-M3IzC"},"outputs":[],"source":["width,height=dataset.data[0].shape\n","number_of_channels=3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UF3qKa8uqxMb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","\n","w =width\n","h = height\n","fig = plt.figure(figsize=(32, 32))\n","columns = 4\n","rows = 5\n","\n","for i in range(1, columns*rows +1):\n","    index = random.randint(0, samples_number)\n","    img = dataset.data[index]\n","    fig.add_subplot(rows, columns, i)\n","    plt.imshow(img)\n","    plt.title(\"give a title to the figure\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Zku4ylweqxMb"},"source":["Prepare the dataset for training:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRa_Y7wBqxMb"},"outputs":[],"source":["X = np.array(dataset.data)/255\n","y = np.array(dataset.target)\n","print(\"Shape X: \", X.shape)\n","print(\"Shape y: \", y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW8xyWBbqxMb"},"outputs":[],"source":["for i in range(10):\n","  print(\"Samples number\"+str(i)+ \" :\", np.count_nonzero(y == i))"]},{"cell_type":"markdown","metadata":{"id":"08rjB07ZqxMc"},"source":["The  classes are balanced, so accuracy is a good metric to use\n","Preprocessing and Spliting the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUG_p07arS3S"},"outputs":[],"source":["X = np.array(dataset.data)\n","y = np.array(dataset.target)\n","train_size=int(len(dataset.data) * 0.80)\n","\n","\n","print(\"train size\",train_size)\n","X_train_full, X_test, y_train_full, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]\n","\n","val_size= int(len(dataset.data) * 0.15)\n","\n","X_valid, X_train = X_train_full[:val_size], X_train_full[val_size:]\n","y_valid, y_train = y_train_full[:val_size], y_train_full[val_size:]\n","\n","\n","\n","print('Shape:', X_train.shape)\n","print('Type:', X_train.dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBOkrCGgcVKO"},"outputs":[],"source":["linear_classifier_accuracy=[]\n","MLP_classifier_accuracy=[]\n","CNN_classifier_accuracy=[]\n","DCNN_classifier_accuracy=[]\n","NN_model_sizes=[]"]},{"cell_type":"markdown","metadata":{"id":"w2ou5uc7qxMe"},"source":["# **NN models**\n","In this section we implement all general functions that can be used by all NN models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5248,"status":"ok","timestamp":1694429519362,"user":{"displayName":"ali dabbous","userId":"07190641217810416394"},"user_tz":-120},"id":"c9qUtpPD_W-e","outputId":"13dfdb0e-3e95-420a-a62a-66b65a047250"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/176.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["pip install -q -U keras-tuner\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJp04gZRsHAe"},"outputs":[],"source":["### import needed libraries\n","!pip install scikit-optimize\n","!pip install memory_profiler\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","import time\n","from memory_profiler import memory_usage\n","import tracemalloc\n","import sklearn\n","from keras.backend import binary_crossentropy\n","import tensorflow as tf\n","from tensorflow import keras\n","import keras_tuner as kt\n","from keras_tuner.tuners import BayesianOptimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6i1nNvyeXnNq"},"outputs":[],"source":["epochs=300\n","batch_size=32\n","def NN_hyperparameter_fit(hyperparameter,Type_model):\n","  if (Type_model==\"CNN\"):\n","    model=build_model(hyperparameter)\n","  if (Type_model==\"DCNN\"):\n","    model=build_model_DCC(hyperparameter)\n","  model.summary()\n","  history = model.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))\n","  plot_model_performance(history,epochs)\n","  return model,history\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttTm2IKkZqaT"},"outputs":[],"source":["def ML_hyperparameters_study(classifier, param_grid, X_train_ML, X_test_ML, y_train_full_ML, y_test_full_ML,random=False):\n","    classifier.random_state = 42\n","    grid_search = GridSearchCV(classifier, param_grid, cv=5, verbose=1)\n","    grid_search.fit(X_train_ML, y_train_full_ML)\n","    results = grid_search.cv_results_\n","    mean_training_score_all = []\n","    params_all = []\n","    testing_accuracy = []\n","    models_size = []\n","    execution_time_list = []\n","    total_allocated_memory=[]\n","    average_allocated_memory=[]\n","    precision_list, recall_list, f1_score_list=[],[],[]\n","\n","    def fit_and_measure_memory(model, X_train_ML, y_train_full_ML):\n","      tracemalloc.start()\n","      start_time = time.time()\n","      model.fit(X_train_ML, y_train_full_ML)\n","      snapshot = tracemalloc.take_snapshot()\n","      tracemalloc.stop()\n","      end_time = time.time()\n","      execution_time_list.append(end_time - start_time)\n","      return snapshot\n","\n","    for mean_score, params in zip(results['mean_test_score'], results['params']):\n","        mean_training_score_all.append(mean_score)\n","        params_all.append(params)\n","        hyper_model = classifier\n","        if random:\n","            hyper_model.random_state = 42\n","        hyper_model.set_params(**params)\n","        snap = fit_and_measure_memory(hyper_model, X_train_ML, y_train_full_ML)\n","        # Calculate the total allocated memory from the snapshot\n","        total_memory=sum(stat.size for stat in snap.statistics('lineno'))\n","        total_allocated_memory.append(format_memory(total_memory))\n","        # Calculate the average allocated memory\n","        num_snapshots = len(snap.statistics('lineno'))\n","        average_allocated_memory.append(format_memory(total_memory / num_snapshots))\n","        y_pred = hyper_model.predict(X_test_ML)\n","        testing_accuracy.append(accuracy_score(y_test_full_ML, y_pred))\n","        precision_value, recall_value, f1_score_value, support_value = sklearn.metrics.precision_recall_fscore_support(y_test_full_ML , y_pred, average= 'weighted' )\n","        precision_list.append(precision_value)\n","        recall_list.append(recall_value)\n","        f1_score_list.append(f1_score_value)\n","        models_size.append(format_memory(calculate_ML_size(hyper_model, \"model(\" + str(mean_score) + \")\")))\n","\n","    best_params = grid_search.best_params_\n","    return [params_all,testing_accuracy,precision_list,recall_list,f1_score_list, models_size, execution_time_list,total_allocated_memory,average_allocated_memory], best_params ,mean_training_score_all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pC_E7_A_qcs4"},"outputs":[],"source":["def evaluate_NN_models(model_list):\n","  loss, accuracy , y_pred ,precision, recall ,f1_score ,support ,confusion_matrix_list = [], [], [], [], [], [], [], []\n","  for model in model_list:\n","    loss_value,accuracy_value=model.evaluate(X_test, y_test)\n","    loss.append(loss_value)\n","    accuracy.append(accuracy_value)\n","    y_pred_value=np.argmax(model.predict(X_test), axis = 1)\n","    y_pred.append(y_pred_value)\n","    precision_value, recall_value, f1_score_value, support_value = sklearn.metrics.precision_recall_fscore_support(y_test , y_pred_value, average= 'weighted' )\n","    precision.append(precision_value)\n","    recall.append(recall_value)\n","    f1_score.append(f1_score_value)\n","    support.append(support_value)\n","    confusion_matrix_value=confusion_matrix(y_test, y_pred_value)\n","    confusion_matrix_list.append(confusion_matrix_value)\n","  return [accuracy ,precision, recall ,f1_score],confusion_matrix_list,y_pred\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9geD5BAKJUg"},"outputs":[],"source":["def plot_model_performace_accuracy(history):\n","  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n","  ax1.plot(history[0].history['accuracy'], 'g', label='Training Accuracy')\n","  ax1.plot(history[0].history['val_accuracy'], color='orange', label='Validation Accuracy')\n","  ax1.set_title('training and validation')\n","  ax1.set_xlabel('epoch')\n","  ax1.set_ylabel('accuracy')\n","  ax1.set_ylim(0.1, 1.01)\n","  ax1.grid(True)\n","  ax1.legend()\n","  ax2.plot(history[1].history['accuracy'], 'g', label='Training Accuracy')\n","  ax2.plot(history[1].history['val_accuracy'], color='orange', label='Validation Accuracy')\n","  ax2.set_title('training and validation')\n","  ax2.set_xlabel('epoch')\n","  ax2.set_ylabel('accuracy')\n","  ax2.set_ylim(0.1, 1.01)\n","  ax2.grid(True)\n","  ax2.legend()\n","  ax3.plot(history[2].history['accuracy'], 'g', label='Training Accuracy')\n","  ax3.plot(history[2].history['val_accuracy'], color='orange', label='Validation Accuracy')\n","  ax3.set_title('training and validation')\n","  ax3.set_xlabel('epoch')\n","  ax3.set_ylabel('accuracy')\n","  ax3.set_ylim(0.1, 1.01)\n","  plt.grid(True)\n","  plt.legend()\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTVrOjZnYxzq"},"outputs":[],"source":["def plot_model_performance(history,number_of_epochs):\n","  print('CNN model training accuracy: ', history.history['accuracy'][number_of_epochs - 1])\n","  print('CNN model validation accuracy: ', history.history['val_accuracy'][number_of_epochs - 1])\n","  plt.figure()\n","  plt.plot(history.history['loss'], 'g', label='Training Loss')\n","  plt.plot(history.history['val_loss'], color='orange', label='Validation Loss')\n","  plt.title('Training and Validation Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('epoch')\n","  plt.legend()\n","  plt.grid(True)\n","  plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7-9-qnH9Q_nR"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(ax, conf_matrix, title, cmap):\n","    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=cmap, cbar=False, ax=ax)\n","    ax.set_title(title)\n","\n","def draw_confusion_matrix(matrix,name):\n","  colormap=[\"Blues\",\"Greens\",\"Oranges\"]\n","  fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","  for i in range(len(matrix)):\n","    plot_confusion_matrix(axes[i], matrix[i], \"Confusion Matrix  \"+name+ str(i+1), colormap[i])\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BF_BtmSWi9Ky"},"outputs":[],"source":["#### function for plotting tables\n","from tabulate import tabulate\n","def print_table(data,headers):\n","  table_data = list(zip(*data))\n","  table = tabulate(table_data, headers=headers, tablefmt='grid')\n","  print(table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82pFChydzcPy"},"outputs":[],"source":["#function to calculate the size of machine learning models\n","import joblib\n","import os\n","def calculate_ML_size(model,file_name):\n","  model_filename = \"/content/\"+file_name+\".joblib\"\n","  joblib.dump(model, model_filename)\n","  file_size = os.path.getsize(model_filename)\n","  return file_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLjH4-0ftyDD"},"outputs":[],"source":["def convert_params_to_list(params_all):\n","  all_keys = set()\n","  for d in params_all:\n","      all_keys.update(d.keys())\n","\n","  data_values = [[d.get(key, None) for d in params_all] for key in all_keys]\n","  return data_values,all_keys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwHHi40t55Z2"},"outputs":[],"source":["def format_memory(memory_bytes):\n","    if memory_bytes < 1024:\n","        return f\"{memory_bytes} B\"\n","    elif memory_bytes < 1024 * 1024:\n","        return f\"{memory_bytes / 1024:.2f} KB\"\n","    elif memory_bytes < 1024 * 1024 * 1024:\n","        return f\"{memory_bytes / (1024 * 1024):.2f} MB\"\n","    else:\n","        return f\"{memory_bytes / (1024 * 1024 * 1024):.2f} GB\""]},{"cell_type":"markdown","metadata":{"id":"4HZGKYdNZNn4"},"source":["# **Linear Classifier (Baseline)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKqtSMxcZui8"},"outputs":[],"source":["X_train_full_ML, X_test_ML, y_train_full_ML, y_test_full_ML = X[:train_size], X[train_size:], y[:train_size], y[train_size:]\n","X_train_ML= np.array([np.array(x_train).reshape(-1) for x_train in X_train_full_ML])\n","X_test_ML=np.array([np.array(x_test).reshape(-1) for x_test in X_test_ML])\n","\n","print('Shape:', X_train_ML.shape)\n","print('Type:', X_train_ML.dtype)\n","print('Shape:', y_train_full_ML.shape)\n","print('Type:', y_train_full_ML.dtype)\n","print('Shape:', X_test_ML.shape)\n","print('Type:', X_test_ML.dtype)\n","print('Shape:', y_test_full_ML.shape)\n","print('Type:', y_test_full_ML.dtype)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSoKU5rLZV0Y"},"outputs":[],"source":["param_grid = {\n","    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n","}\n","\n","# study the performance of DT classifier with tof dataset and different hyperparameters\n","models_info_linear,best_params_linear,mean_training_score_all_linear = ML_hyperparameters_study(SGDClassifier(),param_grid,X_train_ML, X_test_ML, y_train_full_ML, y_test_full_ML,random=True)\n","headers_linear=list(param_grid.keys())\n","\n","#### visulaize all hyperparameters with acuuracy and model size in one table\n","\n","headers_linear=['models','hyperparameters',' accuracy ','precision','recall','f1_score','model size','Runtime','total allocated memory','average allocated memory']\n","data_linear=[['Linear model 1','Linear model 2','Linear model 3','Linear model 4','Linear model 5','Linear model 6']]\n","data_linear.extend(models_info_linear)\n","print_table(data_linear,headers_linear)\n","print(\"best hyperparameter : \", best_params_linear)\n","linear_classifier_accuracy=models_info_linear[1]\n"]},{"cell_type":"markdown","metadata":{"id":"f5K1DhoXXy2o"},"source":["# **Fully connected NN (MLP)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zv4JrzgAXy2w"},"outputs":[],"source":["def build_model_fc(number_of_hidden_layers,number_of_units,learning_rate=0.0001):\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.InputLayer(input_shape=(width, height)))\n","    model.add(tf.keras.layers.Flatten())\n","    for i in range(number_of_hidden_layers):\n","      model.add(tf.keras.layers.Dense( number_of_units[i], activation='relu',kernel_initializer='glorot_uniform'))\n","      model.add(tf.keras.layers.Dropout(rate = 0.3))\n","    model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","     # Compile the model with the hyperparameters\n","    model.compile(optimizer=optimizer,\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'],)\n","    model.summary()\n","    history = model.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))\n","    return model,history"]},{"cell_type":"markdown","metadata":{"id":"Zh8j8vb_Ojxv"},"source":["## Creating grid of hyperparameters values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYi5zHzpOp-v"},"outputs":[],"source":["import random\n","\n","min_num_hidden_layers = 1  # Minimum number of hidden layers\n","max_num_hidden_layers = 5  # Maximum number of hidden layers\n","min_length = 32  # Minimum length of each hidden layer\n","max_length = 256  # Maximum length of each hidden layer\n","num_hidden_layers=[]\n","hidden_layer_lengths = []\n","num_layers = random.randint(min_num_hidden_layers, max_num_hidden_layers)\n","number_of_models=10\n","for _ in range(number_of_models):\n","    num_layers = random.randint(min_num_hidden_layers, max_num_hidden_layers)\n","    num_hidden_layers.append(num_layers)\n","    # Generate a list of random numbers between min_length and max_length and sort them in descending order\n","    layer_lengths = sorted([random.randint(min_length, max_length) for _ in range(num_layers)], reverse=True)\n","    hidden_layer_lengths.append(layer_lengths)\n","\n","\n","for i in range(len(num_hidden_layers)):\n","  print(f\"hidden layer :{num_hidden_layers[i]} , units: {hidden_layer_lengths[i]}\")"]},{"cell_type":"markdown","metadata":{"id":"187VlSXQXy2x"},"source":["## In this section we will **build** and **train** Ten different MLP models each with different hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgUuiADpXy2x"},"outputs":[],"source":["models_list_MLP=[]\n","results_MLP=[]\n","for i in range(len(num_hidden_layers)):\n","  model,results=build_model_fc(num_hidden_layers[i],hidden_layer_lengths[i])\n","  models_list_MLP.append(model)\n","  results_MLP.append(results)\n","  plot_model_performance(results,epochs)"]},{"cell_type":"markdown","metadata":{"id":"AJ29ZnS4O_eH"},"source":["## Choose the best three MLP models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8WkvH0WXy2x"},"outputs":[],"source":["result_all_models_FC,confusion_matrix_FC,predicitions_FC=evaluate_NN_models(models_list_MLP)\n","def find_top_three_indexes(lst):\n","    arr = np.array(lst)\n","    top_indexes = arr.argsort()[-3:][::-1]\n","    return top_indexes\n","\n","# Example usage:\n","top_three_indexes = find_top_three_indexes(result_all_models_FC[0])\n","print(\"Indexes of the top three values:\", top_three_indexes)"]},{"cell_type":"markdown","metadata":{"id":"GccTxLr9PKkR"},"source":["## Let's train the three models with the entire training set:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9n4rf1AXy2x"},"outputs":[],"source":["MLP_best_models=[models_list_MLP[top_three_indexes[0]],models_list_MLP[top_three_indexes[1]],models_list_MLP[top_three_indexes[2]]]\n","model1=MLP_best_models[0]\n","model2=MLP_best_models[1]\n","model3=MLP_best_models[2]\n","results_total_train1 = model1.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n","results_total_train2 = model2.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n","results_total_train3 = model3.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgW2e2BJPSdK"},"outputs":[],"source":["models_list_FC = []\n","models_list_FC.append(model1)\n","models_list_FC.append(model2)\n","models_list_FC.append(model3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsObACmAXy2x"},"outputs":[],"source":["plot_model_performace_accuracy([results_MLP[top_three_indexes[0]],results_MLP[top_three_indexes[0]],results_MLP[top_three_indexes[0]]])"]},{"cell_type":"markdown","metadata":{"id":"0qZ4eHSLXy2x"},"source":["## Evaluate the best three MLP models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqpZMdIgXy2x"},"outputs":[],"source":["result_all_models_FC,confusion_matrix_FC,predicitions_FC=evaluate_NN_models(MLP_best_models)\n","\n","## create a table with all models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score']\n","\n","hyperparameters_values=[]\n","models=[]\n","for i in range(len(top_three_indexes)):\n","  hyperparameters_values.append(f\"{num_hidden_layers[top_three_indexes[i]]},{hidden_layer_lengths[top_three_indexes[i]]}\")\n","  models.append(f\"MLP Model{i}\")\n","data_normal_FC=[models]\n","data_normal_FC.append(hyperparameters_values)\n","data_normal_FC.extend(result_all_models_FC)\n","print_table(data_normal_FC,headers)\n","MLP_classifier_accuracy=result_all_models_FC[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TsMxo78hXy2x"},"outputs":[],"source":["draw_confusion_matrix(confusion_matrix_FC,\"MLP model\")"]},{"cell_type":"markdown","metadata":{"id":"MHN6N68et-_P"},"source":["# **CNN**"]},{"cell_type":"markdown","metadata":{"id":"oyKybPUZG-RV"},"source":["## Let's observe the most performing models and identify their hyperparameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knA-lZadHHEv"},"outputs":[],"source":["def build_model(hp,kernel_size=3):\n","\n","    # Tune the learning rate for the optimizer\n","    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1,1e-2, 1e-3, 1e-4])\n","    # Tune the optimizer\n","    hp_optimizer = hp.Choice('optimizer', values=['adam'])\n","    # Tune the number of filters in the Conv2D layer\n","    hp_filters = hp.Int('filters', min_value=16, max_value=64, step=8)\n","    #tune the dropout values\n","    dropout_rate = hp.Choice('dropout', values=[0.3,0.5])\n","    #tuning weights initialization\n","    kernel_initializer = hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal', 'lecun_normal'])\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n","    model.add(tf.keras.layers.Reshape(target_shape=(width, height, number_of_channels)))\n","    model.add(tf.keras.layers.Conv2D(filters = hp_filters , kernel_size=(kernel_size, kernel_size), activation='relu', kernel_initializer=kernel_initializer))\n","    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","    model.add(tf.keras.layers.Dropout(rate = dropout_rate))\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(10, kernel_initializer=kernel_initializer))\n","    model.add(tf.keras.layers.Activation('softmax'))\n","\n","     # Compile the model with the hyperparameters\n","    model.compile(optimizer=hp_optimizer,\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'],)\n","    return model\n","\n","# Let's use a Bayesian approach to conduct the search.\n","tuner = BayesianOptimization(\n","    build_model,\n","    objective='val_loss',\n","    max_trials=20,\n","    #executions_per_trial=2,\n","    directory='tuner_single_dense',\n","    project_name='training_tuner_single_dense'\n",")\n","\n","#Let's start training models with different hyperparameters.\n","tuner.search(X_train, y_train, epochs=100,batch_size=batch_size, validation_data=(X_valid, y_valid))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xxJO0iYoHi9U"},"outputs":[],"source":["# Get the top 3 hyperparameters.\n","num_trials = 9\n","best_hps2 = tuner.get_best_hyperparameters(num_trials=num_trials)\n","# Print top 3 sets of hyperparameters\n","\n","for idx, hyperparameters in enumerate(best_hps2):\n","    print(f\"Set {idx + 1}: {hyperparameters.values}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYY9Ke1lIS-Y"},"outputs":[],"source":["best_hyperparameter_CNN=[best_hps2[0],best_hps2[3],best_hps2[8]]"]},{"cell_type":"markdown","metadata":{"id":"QL1DrH7wjPfC"},"source":["## Let's compare the accuracy trend on the training set and the validation set as the number of epochs increases for the 3 models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdI_yVdlHsYu"},"outputs":[],"source":["# Build the model with the best hp.\n","model4,results4=NN_hyperparameter_fit(best_hyperparameter_CNN[0],\"CNN\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXnpHDyNJFLo"},"outputs":[],"source":["# Build the model with the second best hp.\n","model5,results5=NN_hyperparameter_fit(best_hyperparameter_CNN[1],\"CNN\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29nxon6fJnUT"},"outputs":[],"source":["# Build the model with the best hp.\n","model6,results6=NN_hyperparameter_fit(best_hyperparameter_CNN[2],\"CNN\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5VMP0aGr3QE"},"outputs":[],"source":["plot_model_performace_accuracy([results4,results5,results6])"]},{"cell_type":"markdown","metadata":{"id":"oaqmNKfujPfF"},"source":["Let's train the three models with the entire training set:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOyltvFRLzZy"},"outputs":[],"source":["results_total_train4 = model4.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n","results_total_train5 = model5.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n","results_total_train6 = model6.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"uF562MkZjPfG"},"source":["## Evaluate on test set:"]},{"cell_type":"markdown","metadata":{"id":"62ylKHm65ayl"},"source":["Adding all models in a list:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WX0fxFp75eHl"},"outputs":[],"source":["models_list_CNN = []\n","models_list_CNN.append(model4)\n","models_list_CNN.append(model5)\n","models_list_CNN.append(model6)"]},{"cell_type":"markdown","metadata":{"id":"L-p3Ldxyuj5j"},"source":["Evaluate All models and print out a table with all parameters (model , hyperparameter, accyracy, precision, recall, f1_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTipflbguwdp"},"outputs":[],"source":["result_all_models_CNN,confusion_matrix_CNN,predicitions=evaluate_NN_models(models_list_CNN)\n","## create a table with all models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score']\n","data_normal_CNN=[['CNN model 1',' CNN model 2', 'CNN model 3']]\n","\n","hyperparameters_values=[]\n","# Print top 3 sets of hyperparameters\n","for idx, hyperparameters in enumerate(best_hyperparameter_CNN):\n","  hyperparameters_values.append(hyperparameters.values)\n","data_normal_CNN.append(hyperparameters_values)\n","data_normal_CNN.extend(result_all_models_CNN)\n","print_table(data_normal_CNN,headers)\n","CNN_classifier_accuracy=result_all_models_CNN[0]\n"]},{"cell_type":"markdown","metadata":{"id":"Kkb3ECFBadPY"},"source":["Draw confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2laHmAfCafQm"},"outputs":[],"source":["draw_confusion_matrix(confusion_matrix_CNN,\"CNN model\")"]},{"cell_type":"markdown","metadata":{"id":"J4dgcL2Xd8Bx"},"source":["# **Deeper CNN (DCNN)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kl1zAgVepvHl"},"outputs":[],"source":["### number_of_convolutional : the number of convolutional layer\n","### kernal_size : a list of kernal sizes for each convolutional layer repespectively\n","def build_model_DCC(hp,number_of_convolutional=2,kernal_size=[5,3]):\n","\n","    # Tune the learning rate for the optimizer\n","    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2,1e-3,1e-4])\n","    # Tune the optimizer\n","    hp_optimizer = hp.Choice('optimizer', values=['adam'])\n","    # Tune the number of filters in the Conv2D layer\n","    hp_filters = hp.Int('filters', min_value=16, max_value=64, step=8)\n","    #tune the dropout values\n","    dropout_rate = hp.Choice('dropout', values=[0.3,0.5])\n","    #tuning weights initialization\n","    kernel_initializer = hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal', 'lecun_normal'])\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n","    # model.add(tf.keras.layers.Reshape(target_shape=(width, height, number_of_channels)))\n","\n","    for i in range(number_of_convolutional - 1):\n","      model.add(tf.keras.layers.Conv2D(filters = hp_filters , kernel_size=(kernal_size[i], kernal_size[i]), activation='relu',padding='same', kernel_initializer=kernel_initializer))\n","      model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","      model.add(tf.keras.layers.Dropout(rate = dropout_rate))\n","\n","    model.add(tf.keras.layers.Conv2D(filters = hp_filters , kernel_size=(kernal_size[len(kernal_size)-1], kernal_size[len(kernal_size)-1]), activation='relu',padding='same', kernel_initializer=kernel_initializer))\n","\n","\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(10, kernel_initializer=kernel_initializer))\n","    model.add(tf.keras.layers.Activation('softmax'))\n","\n","    # Compile the model with the hyperparameters\n","    model.compile(optimizer=hp_optimizer,\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","# Let's use a Bayesian approach to conduct the search.\n","tuner = BayesianOptimization(\n","    build_model_DCC,\n","    objective='val_loss',\n","    max_trials=20,\n","    #executions_per_trial=2,\n","    directory='tuner_single_dense',\n","    project_name='training_tuner_single_dense16'\n",")\n","\n","#Let's start training models with different hyperparameters.\n","tuner.search(X_train, y_train, epochs=75,batch_size=batch_size, validation_data=(X_valid, y_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trssd2pSyOUT"},"outputs":[],"source":["# Get the top 3 hyperparameters.\n","num_trials = 6\n","best_hps_DCNN = tuner.get_best_hyperparameters(num_trials=num_trials)\n","# Print top 3 sets of hyperparameters\n","\n","for idx, hyperparameters in enumerate(best_hps_DCNN):\n","    print(f\"Set {idx + 1}: {hyperparameters.values}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHg-f69aIcNX"},"outputs":[],"source":["best_hyperparameter_DCNN=[best_hps_DCNN[0],best_hps_DCNN[1],best_hps_DCNN[2]]"]},{"cell_type":"markdown","metadata":{"id":"JfPtfsRjyyTf"},"source":["## Train three models with the three best hyperparameters and study the performance of the model with validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rITqbBjgycvC"},"outputs":[],"source":["model7,results7=NN_hyperparameter_fit(best_hyperparameter_DCNN[0],\"DCNN\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5UUQavzclXO"},"outputs":[],"source":["model7.get_layer(name=\"conv2d_6\").kernel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpLrskL5yp1d"},"outputs":[],"source":["model8,results8=NN_hyperparameter_fit(best_hyperparameter_DCNN[1],\"DCNN\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2dFvtJMyp93"},"outputs":[],"source":["model9,results9=NN_hyperparameter_fit(best_hyperparameter_DCNN[2],\"DCNN\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDGmglKZzCOq"},"outputs":[],"source":["plot_model_performace_accuracy([results7,results8,results9])"]},{"cell_type":"markdown","metadata":{"id":"tT2l5Hpcy9aD"},"source":["train the model on all the entire dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmXW-fQUzA0j"},"outputs":[],"source":["results_total_train7 = model7.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n","results_total_train8 = model8.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)\n","results_total_train9 = model9.fit(X_train_full, y_train_full, epochs=epochs,batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"DBaWG5NBzbtU"},"source":["## Adding all DCNN models to a list to start evaluating on testing dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlZ0S2HrzhPR"},"outputs":[],"source":["models_list_DCNN = []\n","models_list_DCNN.append(model7)\n","models_list_DCNN.append(model8)\n","models_list_DCNN.append(model9)"]},{"cell_type":"markdown","metadata":{"id":"6bXDmagDzvnu"},"source":["Evaluate All models and print out a table with all parameters (model , hyperparameter, accyracy, precision, recall, f1_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEieZUhFzwT0"},"outputs":[],"source":["result_all_models_DCNN,confusion_matrix_DCNN,predicitions=evaluate_NN_models(models_list_DCNN)\n","## create a table with all models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score']\n","data_normal_DCNN=[['DCNN model 1',' DCNN model 2', 'DCNN model 3']]\n","\n","hyperparameters_values=[]\n","# Print top 3 sets of hyperparameters\n","for idx, hyperparameters in enumerate(best_hyperparameter_DCNN):\n","  hyperparameters_values.append(hyperparameters.values)\n","data_normal_DCNN.append(hyperparameters_values)\n","data_normal_DCNN.extend(result_all_models_DCNN)\n","print_table(data_normal_DCNN,headers)\n","DCNN_classifier_accuracy=result_all_models_DCNN[0]"]},{"cell_type":"markdown","metadata":{"id":"33BXAYYZ0P0S"},"source":["Draw confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMuVC7UJ0RuW"},"outputs":[],"source":["draw_confusion_matrix(confusion_matrix_DCNN,\"DCNN model\")"]},{"cell_type":"markdown","metadata":{"id":"UUU_a3XeqxMq"},"source":["\n","# **TensorFlow Lite model**\n"]},{"cell_type":"markdown","metadata":{"id":"fAK7VfJsbGfQ"},"source":["## functions to evaluate and print analysis for  tf lite / quantized models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7SYQ3xYqxMr"},"outputs":[],"source":["import numpy as np\n","\n","def evaluate(model_file, X, y, categoricalAccuarcy):\n","    if(categoricalAccuarcy):\n","      accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","    else:\n","      accuracy = tf.keras.metrics.BinaryAccuracy()\n","\n","    interpreter = tf.lite.Interpreter(model_path = model_file)\n","    interpreter.allocate_tensors()\n","    input_details = interpreter.get_input_details()[0]\n","    output_details = interpreter.get_output_details()[0]\n","\n","    y_preds = []\n","    y_real = []\n","\n","    for x, y_true in zip(X,y):\n","        if input_details['dtype'] == np.uint8:\n","            input_scale, input_zero_point = input_details[\"quantization\"]\n","            x = x / input_scale + input_zero_point\n","        x = np.expand_dims(x, axis=0).astype(input_details[\"dtype\"])\n","        interpreter.set_tensor(input_details[\"index\"], x)\n","        interpreter.invoke()\n","        y_pred = interpreter.get_tensor(output_details[\"index\"])[0]\n","        accuracy.update_state(y_true, y_pred)\n","         # Collect the predicted labels\n","        if(categoricalAccuarcy):\n","            y_preds.append(np.argmax(y_pred))\n","        else:\n","            y_preds.append(np.round(y_pred[0]))\n","\n","        y_real.append(y_true)\n","    return accuracy.result(), y_preds, y_real"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AwkNvbTqxMr"},"outputs":[],"source":["\n","def evaluate_tflite_quantized_models(models_list,base_filename_model,models_files,full=False):\n","  tflite_model_accuracy,tflite_model_predicitons,y_true,precisions_tf_lite_model,recalls_tf_lite_model,f1_scores_tf_lite_model,confusion_tflite_matrix_list = [], [], [] ,[],[], [], []\n","  for i in range(len(models_list)):\n","    path = base_filename_model + '/' + models_files[i].name\n","    print(\"path\",path)\n","    accuracy, y_pred, y_real = evaluate(path, X_test, y_test, True)\n","    tflite_model_accuracy.append(accuracy.numpy())\n","    tflite_model_predicitons.append(y_pred)\n","    y_true.append(y_real)\n","    precision_value, recall_value, f1_score_value, support_value = sklearn.metrics.precision_recall_fscore_support(y_real , y_pred, average= 'weighted' )\n","    precisions_tf_lite_model.append(precision_value)\n","    recalls_tf_lite_model.append(recall_value)\n","    f1_scores_tf_lite_model.append(f1_score_value)\n","    confusion_matrix_value=confusion_matrix(y_test, y_pred)\n","    confusion_tflite_matrix_list.append(confusion_matrix_value)\n","  return [tflite_model_accuracy,precisions_tf_lite_model,recalls_tf_lite_model,f1_scores_tf_lite_model],confusion_tflite_matrix_list,tflite_model_predicitons\n"]},{"cell_type":"markdown","metadata":{"id":"1a-Z7foywbsu"},"source":["## Converting all models to tflite model using tensorflow lite converter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVC6TsGTt5ku"},"outputs":[],"source":["models_list=[model1,model2,model3,model4,model5,model6,model7,model8,model9]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7cNq4bhqxMq"},"outputs":[],"source":["tflite_models = []\n","\n","for index in range(len(models_list)):\n","  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[index])\n","  tflite_models.append(converter.convert())"]},{"cell_type":"markdown","metadata":{"id":"VeAumtFjqxMq"},"source":["## It's now a TensorFlow Lite model, but it's still using 32-bit float values for all parameter data. We can store the models in a file in order to estimate its size:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hN1FkWBkqxMq"},"outputs":[],"source":["import pathlib\n","import os\n","tflite_models_dir = pathlib.Path(\"./\")\n","base_filename_model_tflite = 'tflite_model'\n","path = tflite_models_dir/base_filename_model_tflite\n","\n","if not os.path.exists(path):\n","  os.makedirs(path)\n","\n","tflite_model_files = []\n","tflite_model_size = []\n","\n","for i in range(1, len(models_list) +1):\n","  filename = f\"{base_filename_model_tflite}_{i}.tflite\"\n","  tflite_model_files.append(path/filename)\n","  tflite_model_files[i-1].write_bytes(tflite_models[i-1])\n","  tflite_model_size.append(os.path.getsize(tflite_model_files[i -1]) / float(2**10))\n","  print(\"TFlite model in KB:\", tflite_model_size[i-1])"]},{"cell_type":"markdown","metadata":{"id":"JF5adl6njPfJ"},"source":["## Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mo3mhz-OZGfD"},"outputs":[],"source":["tflite_all_results, confusion_tflite_all, tflite_predictions = evaluate_tflite_quantized_models(models_list,base_filename_model_tflite,tflite_model_files)\n","## create a table with all tf lite models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n","data_tflite=[['tflite MLP model 1','tflite MLP model 2', 'tflite MLP model 3',\n","              'tflite CNN model 1','tflite CNN model 2', 'tflite CNN model 3',\n","              'tflite DCNN model 1','tflite DCNN model 2', 'tflite DCNN model 3']]\n","hyperparameters_values=[]\n","\n","\n","\n","for j in range(len(FC_hyperparameter)):\n","  units=\"\"\n","  for i in range(1,FC_hyperparameter[j][0]+1):\n","    units += str(int(FC_hyperparameter[j][1]/i)) + \",\"\n","  hyperparameters_values.append(\"{ hidden layers: \" + str(FC_hyperparameter[j][0]) + \" units: \" + units +\" }\")\n","\n","for idx, hyperparameters in enumerate(best_hyperparameter_CNN):\n","  hyperparameters_values.append(hyperparameters.values)\n","\n","for idx, hyperparameters in enumerate(best_hyperparameter_DCNN):\n","  hyperparameters_values.append(hyperparameters.values)\n","\n","data_tflite.append(hyperparameters_values)\n","data_tflite.extend(tflite_all_results)\n","data_tflite.append(tflite_model_size)\n","print_table(data_tflite,headers)\n","NN_model_sizes=tflite_model_size"]},{"cell_type":"markdown","metadata":{"id":"8JRZqEpUqxMr"},"source":["# **Post-training quantization**\n","\n","We can enable the default optimizations flag to quantize all fixed parameters (weights and biases) to 8-bit integers. Notice that scale and zero point for weights and bias can be calculated before the inference, becouse their ranges are already available. But how we can calculate scale and zero point for activations? We can use the **dynamic quantization**, in which scale and zero point for activations are calculated on-the-fly (online during inference). This means that the activations are always stored in float 32 and they are converted to integers while processing and back to floating point after the processing is done.\n"]},{"cell_type":"markdown","metadata":{"id":"xLvlcFezxB7z"},"source":["## TFlite Dynamic Quantization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvE7tJamqxMr"},"outputs":[],"source":["tflite_dynamic_quantized_models = []\n","\n","for i in range (0 , len(models_list)):\n","  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[i])\n","  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","  tflite_dynamic_quantized_models.append(converter.convert())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfbztuEiqxMs"},"outputs":[],"source":["tflite_dynamic_quantized_model_files = []\n","tflite_dynamic_quantized_model_size = []\n","\n","base_filename_dynamic = 'tflite_dynamic_quantized_model'\n","path = tflite_models_dir/base_filename_dynamic\n","\n","if not os.path.exists(path):\n","  os.makedirs(path)\n","\n","for i in range (1, len(models_list) + 1):\n","  file_name =  f\"{base_filename_dynamic}_{i}.tflite\"\n","  tflite_dynamic_quantized_model_files.append(path/file_name)\n","  tflite_dynamic_quantized_model_files[i-1].write_bytes(tflite_dynamic_quantized_models[i-1])\n","  tflite_dynamic_quantized_model_size.append(os.path.getsize(tflite_dynamic_quantized_model_files[i - 1]) / float(2**10))\n","  print(\"TFlite dynamic quantized model in KB:\", tflite_dynamic_quantized_model_size[i-1])"]},{"cell_type":"markdown","metadata":{"id":"uGcAO554criq"},"source":["### Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model_dynamic_models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3JMRv6MXD46"},"outputs":[],"source":["dynamic_quantized_all_results, confusion_dynamic_quantized_all, dynamic_quantized_predictions = evaluate_tflite_quantized_models(models_list,base_filename_dynamic,tflite_dynamic_quantized_model_files)\n","## create a table with all tf lite models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n","data_dynamic_quantized=[['Dynamic quantized MLP model 1','Dynamic quantized MLP model 2', 'Dynamic quantized MLP model 3',\n","                         'Dynamic quantized CNN model 1','Dynamic quantized CNN model 2', 'Dynamic quantized CNN model 3',\n","                        'Dynamic quantized DCNN model 1','Dynamic quantized DCNN model 2', 'Dynamic quantized DCNN model 3']]\n","data_dynamic_quantized.append(hyperparameters_values)\n","data_dynamic_quantized.extend(dynamic_quantized_all_results)\n","data_dynamic_quantized.append(tflite_dynamic_quantized_model_size)\n","print_table(data_dynamic_quantized,headers)"]},{"cell_type":"markdown","metadata":{"id":"VnsT3qFDjPfP"},"source":["## Static Quantization\n","The model is now smaller with quantized weights with some decrease in the accuracy, but other variable data are still in float format. To quantize variable data (input/output and intermediates between layers), we can use **static quantization** to pre-computes scales and zero points also for all variable data in order to eliminate this overhead. However, we need some representative data in order to collect the distribution statistics for all the variable data and compute an estime of scales and zero points. The short-coming is that if the data is not representative, the scales and zero points computed might not reflect the true scenario during inference, and the inference accuracy will be harmed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnE_UlZkqxMt"},"outputs":[],"source":["def representative_data_gen():\n","  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n","      input_value = tf.cast(input_value, tf.float32)\n","      yield [input_value]\n","\n","tflite_static_quantized_models = []\n","\n","for i in range (0 , len(models_list)):\n","  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[i])\n","  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","  converter.representative_dataset = representative_data_gen\n","  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","\n","  # Convert the model to a quantized TFLite model\n","  tflite_static_quantized_models.append(converter.convert())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXfL2hewqxMt"},"outputs":[],"source":["tflite_static_quantized_model_files = []\n","tflite_static_quantized_model_size = []\n","\n","base_filename_static = 'tflite_static_quantized_model'\n","path = tflite_models_dir/base_filename_static\n","\n","if not os.path.exists(path):\n","  os.makedirs(path)\n","\n","for i in range (1, len(models_list) + 1):\n","  file_name =  f\"{base_filename_static}_{i}.tflite\"\n","  tflite_static_quantized_model_files.append(path/file_name)\n","  tflite_static_quantized_model_files[i - 1].write_bytes(tflite_static_quantized_models[i - 1])\n","  tflite_static_quantized_model_size.append(os.path.getsize(tflite_static_quantized_model_files[i - 1]) / float(2**10))\n","  print(\"TFlite static quantized model in KB:\", tflite_static_quantized_model_size[i-1])"]},{"cell_type":"markdown","metadata":{"id":"mx5wtz8xjPfQ"},"source":["### Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model_static_models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ef3jL6hKqxMt"},"outputs":[],"source":["static_quantized_all_results, confusion_static_quantized_all, static_quantized_predictions = evaluate_tflite_quantized_models(models_list,base_filename_static,tflite_static_quantized_model_files)\n","## create a table with all tf lite models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n","data_static_quantized=[['Static quantized MLP model 1','Static quantized MLP model 2', 'Static quantized MLP model 3',\n","                        'Static quantized CNN model 1','Static quantized CNN model 2', 'Static quantized CNN model 3',\n","                        'Static quantized DCNN model 1','Static quantized DCNN model 2', 'Static quantized DCNN model 3']]\n","data_static_quantized.append(hyperparameters_values)\n","data_static_quantized.extend(static_quantized_all_results)\n","data_static_quantized.append(tflite_static_quantized_model_size)\n","print_table(data_static_quantized,headers)"]},{"cell_type":"markdown","metadata":{"id":"V3_niyOBqxMt"},"source":["## Full static Quantization\n","Now all weights and variable data are quantized. However, to maintain compatibility with applications that traditionally use float model, the TensorFlow Lite Converter leaves the model input and output tensors in float. This is good for compatibility, but it won't be compatible with devices that perform only integer-based operations. To ensure end-to-end integer-only model, we need to specify some parameters to the converter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRfn9vIMqxMu"},"outputs":[],"source":["tflite_full_static_quantized_models = []\n","\n","for i in range(0, len(models_list)):\n","  converter = tf.lite.TFLiteConverter.from_keras_model(models_list[i])\n","  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","  converter.representative_dataset = representative_data_gen\n","  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","  converter.inference_input_type = tf.uint8\n","  converter.inference_output_type = tf.uint8\n","  tflite_full_static_quantized_models.append(converter.convert())"]},{"cell_type":"markdown","metadata":{"id":"xFtAoEXSqxMu"},"source":["### The internal quantization remains the same as above, but we can see the input and output tensors are now integer format:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iCvHPMMqxMu"},"outputs":[],"source":["interpreter = tf.lite.Interpreter(model_content = tflite_full_static_quantized_models[0])\n","input_type = interpreter.get_input_details()[0]['dtype']\n","print('input: ', input_type)\n","output_type = interpreter.get_output_details()[0]['dtype']\n","print('output: ', output_type)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLJ3UUXPqxMu"},"outputs":[],"source":["tflite_full_static_quantized_model_files = []\n","tflite_full_static_quantized_model_size = []\n","\n","base_filename_full_static = 'tflite_full_static_quantized_model'\n","path = tflite_models_dir/base_filename_full_static\n","\n","if not os.path.exists(path):\n","  os.makedirs(path)\n","\n","for i in range(1, len(models_list) + 1) :\n","  file_name =  f\"{base_filename_full_static}_{i}.tflite\"\n","  tflite_full_static_quantized_model_files.append(path/file_name)\n","  tflite_full_static_quantized_model_files[i - 1].write_bytes(tflite_full_static_quantized_models[i - 1])\n","  tflite_full_static_quantized_model_size.append(os.path.getsize(tflite_full_static_quantized_model_files[i - 1]) / float(2**10))\n","  print(\"TFlite full static quantized model in KB:\", tflite_full_static_quantized_model_size[i-1])"]},{"cell_type":"markdown","metadata":{"id":"uyYekcEYjPfT"},"source":["### Evaluate and Calculate Accuracy, Precision, Recall, F1 Tf_lite_model_full_static_models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2KDJ1qtqxMu"},"outputs":[],"source":["full_static_quantized_all_results, confusion_full_static_quantized_all, full_static_quantized_predictions = evaluate_tflite_quantized_models(models_list,base_filename_full_static,tflite_full_static_quantized_model_files,full=True)\n","## create a table with all tf lite models results\n","headers=['models','hyperparameter','accuracy','precision','recall','f1_score','model size KB']\n","data_full_static_quantized=[['Full static quantized MLP model 1','full static quantized MLP model 2', 'full static quantized MLP model 3',\n","                             'Full static quantized CNN model 1','full static quantized CNN model 2', 'full static quantized CNN model 3',\n","                             'Full static quantized DCNN model 1','full static quantized DCNN model 2', 'full static quantized DCNN model 3']]\n","data_full_static_quantized.append(hyperparameters_values)\n","data_full_static_quantized.extend(full_static_quantized_all_results)\n","data_full_static_quantized.append(tflite_full_static_quantized_model_size)\n","print_table(data_full_static_quantized,headers)"]},{"cell_type":"markdown","metadata":{"id":"HmCqpGjTf-DT"},"source":["# **Best models**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jla4e1q_2qv6"},"outputs":[],"source":["linear_index=linear_classifier_accuracy.index(max(linear_classifier_accuracy))\n","MLP_index=MLP_classifier_accuracy.index(max(MLP_classifier_accuracy))\n","CNN_index=CNN_classifier_accuracy.index(max(CNN_classifier_accuracy))\n","DCNN_index=DCNN_classifier_accuracy.index(max(DCNN_classifier_accuracy))\n","print(linear_index,MLP_index,CNN_index,DCNN_index)\n","\n","tflite_modelfiles_best=[tflite_model_files[MLP_index],tflite_model_files[CNN_index + 3],tflite_model_files[DCNN_index + 6]]\n","dynamic_modelfiles_best=[tflite_dynamic_quantized_model_files[MLP_index],tflite_dynamic_quantized_model_files[CNN_index + 3],tflite_dynamic_quantized_model_files[DCNN_index + 6]]\n","static_modelfiles_best=[tflite_static_quantized_model_files[MLP_index],tflite_static_quantized_model_files[CNN_index + 3],tflite_static_quantized_model_files[DCNN_index + 6]]\n","print(tflite_modelfiles_best,dynamic_modelfiles_best,static_modelfiles_best)\n","FC_best_hp=FC_hyperparameter[MLP_index]\n","CNN_best_hp=best_hyperparameter_CNN[CNN_index]\n","DCNN_best_hp=best_hyperparameter_DCNN[DCNN_index]\n","print(FC_best_hp)\n"]},{"cell_type":"markdown","metadata":{"id":"aU0BlqEQjPfU"},"source":["# **Quantization Aware Training**\n","Quantization introduces information loss and therefore the inference accuracy from the quantized integer models are inevitably lower than that from the floating point models. Such information loss is due to that the floating points after quantization and de-quantization is not exactly recoverable. The idea of quantization aware training is to ask the neural network to take the effect of such information loss into account during training. We can use the TensorFlow Model Optimization toolkit and passing in input the Keras model. What that API is doing is extending that network with the ability to mimic the quantized behavior that would be happening during the inference time, during the training time.# Aware Quantization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_80xQHD3rr8m"},"outputs":[],"source":["!pip install tensorflow-model-optimization"]},{"cell_type":"markdown","metadata":{"id":"zBSLFU-3Kf3f"},"source":["## Functions for building aware MLP, CNN and DCNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YEDJvoWOqxMv"},"outputs":[],"source":["def build_model_aware_CNN(quantizator,kernel_size=3):\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n","    model.add(tf.keras.layers.Reshape(target_shape=(width, height, number_of_channels)))\n","    model.add(tf.keras.layers.Conv2D(32 , kernel_size=(kernel_size, kernel_size), activation='relu', kernel_initializer=\"glorot_uniform\"))\n","    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","    model.add(tf.keras.layers.Dropout(rate = 0.5))\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(10, kernel_initializer=\"glorot_uniform\"))\n","    model.add(tf.keras.layers.Activation('softmax'))\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","    quantization_aware_model = quantizator(model)\n","    # Compile the model with the hyperparameters\n","    quantization_aware_model.compile(optimizer=optimizer,\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'],)\n","    quantization_aware_model.summary()\n","\n","    return quantization_aware_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7kxZ1mI9i9u"},"outputs":[],"source":["def build_model_aware_fc(quantizator,number_of_hidden_layers=2,number_of_units=128):\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n","    model.add(tf.keras.layers.Flatten())\n","    for i in range(1,number_of_hidden_layers+1):\n","      model.add(tf.keras.layers.Dense( number_of_units/i, activation='relu'))\n","      model.add(tf.keras.layers.Dropout(rate = 0.3))\n","    model.add(tf.keras.layers.Dense(10,activation='softmax'))\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","    quantization_aware_model = quantizator(model)\n","     # Compile the model with the hyperparameters\n","    quantization_aware_model.compile(optimizer=\"adam\",\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'],)\n","    quantization_aware_model.summary()\n","    return quantization_aware_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbK5vW3VA9FS"},"outputs":[],"source":["def build_model_aware_DCNN(quantizator,number_of_convolutional=2,kernal_size=[5,3]):\n","\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.InputLayer(input_shape=(width, height,number_of_channels)))\n","    model.add(tf.keras.layers.Reshape(target_shape=(width, height, number_of_channels)))\n","\n","    for i in range(1,number_of_convolutional):\n","      model.add(tf.keras.layers.Conv2D(64 , kernel_size=(kernal_size[i], kernal_size[i]), activation='relu', kernel_initializer=\"glorot_uniform\"))\n","      model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","      model.add(tf.keras.layers.Dropout(rate = 0.3))\n","\n","    model.add(tf.keras.layers.Conv2D(64 , kernel_size=(kernal_size[len(kernal_size)-1], kernal_size[len(kernal_size)-1]), activation='relu', kernel_initializer=\"glorot_uniform\"))\n","\n","\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(10, kernel_initializer=\"glorot_uniform\"))\n","    model.add(tf.keras.layers.Activation('softmax'))\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","    quantization_aware_model = quantizator(model)\n","    quantization_aware_model.compile(optimizer=optimizer,\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'],)\n","    quantization_aware_model.summary()\n","    return quantization_aware_model"]},{"cell_type":"markdown","metadata":{"id":"hl0benL7LYZI"},"source":["## build models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_XJABxLzEaG"},"outputs":[],"source":["## since our study on three different comination of the hyperparameters we will create three aware training quantizations models in order to compare the results\n","import tensorflow_model_optimization as tfmot\n","quantizator = tfmot.quantization.keras.quantize_model\n","quantization_aware_model1=build_model_aware_fc(quantizator)\n","quantization_aware_model2=build_model_aware_CNN(quantizator)\n","quantization_aware_model3=build_model_aware_DCNN(quantizator)\n"]},{"cell_type":"markdown","metadata":{"id":"M6ccqFczqxMv"},"source":["## When we train the networks, it is implicitly learning to be resilient to the quantization error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IL-MNu4OqxMv"},"outputs":[],"source":["aware_results1 = quantization_aware_model1.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))\n","aware_results2 = quantization_aware_model2.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))\n","aware_results3 = quantization_aware_model3.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_valid, y_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu6zTcY_qxMw"},"outputs":[],"source":["plot_model_performace_accuracy([aware_results1,aware_results2,aware_results3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRs0p9y1A32P"},"outputs":[],"source":["aware_model_list=[quantization_aware_model1,quantization_aware_model2,quantization_aware_model3]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcylnWd8qxMw"},"outputs":[],"source":["tflite_aware_quantized_models = []\n","for i in range(0, len(aware_model_list)):\n","  converter = tf.lite.TFLiteConverter.from_keras_model(aware_model_list[i])\n","  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","  converter.representative_dataset = representative_data_gen\n","  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","  converter.inference_input_type = tf.uint8\n","  converter.inference_output_type = tf.uint8\n","  tflite_aware_quantized_models.append(converter.convert())\n","\n","interpreter = tf.lite.Interpreter(model_content = tflite_aware_quantized_models[0])\n","input_type = interpreter.get_input_details()[0]['dtype']\n","print('input: ', input_type)\n","output_type = interpreter.get_output_details()[0]['dtype']\n","print('output: ', output_type)\n","\n","tflite_aware_quantized_model_files = []\n","tflite_aware_quantized_model_size = []\n","\n","base_filename_aware = 'tflite_aware_quantized_model'\n","path = tflite_models_dir/base_filename_aware\n","\n","if not os.path.exists(path):\n","  os.makedirs(path)\n","\n","for i in range(1, len(aware_model_list) + 1) :\n","  file_name =  f\"{base_filename_aware}_{i}.tflite\"\n","  tflite_aware_quantized_model_files.append(path/file_name)\n","  tflite_aware_quantized_model_files[i - 1].write_bytes(tflite_aware_quantized_models[i - 1])\n","  tflite_aware_quantized_model_size.append(os.path.getsize(tflite_aware_quantized_model_files[i - 1]) / float(2**10))\n","  print(\"TFlite aware quantized model in KB:\", tflite_aware_quantized_model_size[i-1])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ouJIZDJRjPfW"},"source":["## Calculate Accuracy, Precision, Recall, F1 Tf_lite_aware_quantized_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ygt18mgzqxMw"},"outputs":[],"source":["aware_quantized_all_results, confusion_aware_quantized_all, aware_quantized_predictions = evaluate_tflite_quantized_models(aware_model_list,base_filename_aware,tflite_aware_quantized_model_files,full=True)\n","## create a table with all tf lite models results\n","headers=['models','accuracy','precision','recall','f1_score','model size KB']\n","data_aware_quantized=[['Aware quantized MLP model ','Aware quantized model CNN ', 'Aware quantized DCNN model ']]\n","# units=\"\"\n","# for i in range(FC_best_hp[0]):\n","#   units + str(FC_best_hp[1]/i) + \",\"\n","# hyperparameters_values=[\"{ hidden layers: \" + str(FC_best_hp[0]) + \"units: \" + units +\" }\",CNN_best_hp.values,DCNN_best_hp.values]\n","# data_aware_quantized.append(hyperparameters_values)\n","data_aware_quantized.extend(aware_quantized_all_results)\n","data_aware_quantized.append(tflite_aware_quantized_model_size)\n","print_table(data_aware_quantized,headers)"]},{"cell_type":"markdown","metadata":{"id":"3ffK-qn1EZE3"},"source":["# **Benchmark Models with STM tools**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZrtTZTi01aq"},"outputs":[],"source":["# download from github requirement.txt\n","import requests\n","\n","github_file_url = 'https://github.com/STMicroelectronics/stm32ai-modelzoo/blob/main/requirements.txt'\n","local_file_path = 'requirements.txt'\n","\n","response = requests.get(github_file_url)\n","\n","if response.status_code == 200:\n","    json_data = response.json()  # Converti la risposta in JSON\n","    file_content = json_data['payload']['blob']['rawLines']  # Estrai il contenuto del file\n","\n","    with open(local_file_path, 'w') as file:\n","        for line in file_content:\n","            file.write(line + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQr7_l_YFXwE"},"outputs":[],"source":["#install package defined in requirement.txt\n","!pip install -r ./requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VoSVfdhuEgGu"},"outputs":[],"source":["import os\n","os.environ[\"STM32AI_USERNAME\"] = \"alexb7396@gmail.com\"\n","os.environ[\"STM32AI_PASSWORD\"] = \"Carlobarabino1996.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oB2Lz7IcKOfu"},"outputs":[],"source":["import sys\n","!{sys.executable} -m pip install pycurl seaborn numpy matplotlib\n","!{sys.executable} -m pip install ipywidgets\n","!{sys.executable} -m pip install gitdir\n","!{sys.executable} -m pip install shutils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kYxsji4L-No"},"outputs":[],"source":["import os\n","import shutil\n","# Get STM32Cube.AI Developer Cloud\n","!gitdir https://github.com/STMicroelectronics/stm32ai-modelzoo/tree/main/common/stm32ai_dc\n","\n","# Reorganize local folders\n","if os.path.exists('./stm32ai_dc'):\n","    shutil.rmtree('./stm32ai_dc')\n","shutil.move('./common/stm32ai_dc', './stm32ai_dc')\n","shutil.rmtree('./common')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B10qsQH1MJC2"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import ipywidgets as widgets\n","\n","sys.path.append(os.path.abspath('stm32ai'))\n","os.environ['STATS_TYPE'] = 'jupyter_devcloud'\n","\n","os.makedirs('models', exist_ok=True)\n","os.makedirs('outputs', exist_ok=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQpJKoM-paeN"},"outputs":[],"source":["import sys\n","import os\n","\n","# Append sys.path in order to add import folder for STM32AI\n","dir_name = os.path.dirname('./')\n","sys.path.insert(0, os.path.abspath(os.path.join(dir_name, '..')))\n","sys.path.append(os.path.abspath('../../../common'))\n","from stm32ai_dc import Stm32Ai, CloudBackend, CliParameters\n","from stm32ai_dc.errors import ParameterError, BenchmarkServerError\n","\n","# Get username/password from environment\n","username = os.environ.get('STM32AI_USERNAME', None)\n","password = os.environ.get('STM32AI_PASSWORD', None)\n","\n","results = []\n","\n","# Create STM32AI Class with Cloud Backend, given a username/password and a possible version\n","# Version set to \"None\" will use the latest version available in Developer Cloud\n","ai = Stm32Ai(CloudBackend(username, password, version=None))\n","\n","# List boards available for a benchmark in STM32Cube.AI Developer Cloud\n","boards = ai.get_benchmark_boards()\n","\n","\n","# Boards length should be greater than zero\n","# A length equals to zero mean a current maintenance or a failure\n","if len(boards) == 0:\n","    print(\"No board detected remotely, can't start benchmark\")\n","    sys.exit(0)\n","\n","boards\n"]},{"cell_type":"markdown","metadata":{"id":"1-X3Yp3epgXt"},"source":["# **Benchmark models on ST boards**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQ0WexL1aU0c"},"outputs":[],"source":["#uploading models to ST\n","def upload_model(number_of_models,base_file_name_model,model_file_names):\n","\n","  model_names=[]\n","  for i in range(number_of_models):\n","    path_model = base_file_name_model + '/' + model_file_names[i].name\n","    ai.upload_model(path_model)\n","    model_names.append(model_file_names[i].name)\n","  return model_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nd0yH0VxbFlr"},"outputs":[],"source":["#deleting model from ST\n","def delete_model(number_of_models,model_names):\n","  for i in range(number_of_models):\n","    model_name=model_names[i]\n","    ai.delete_model(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SXwGGe2bhtH"},"outputs":[],"source":["### Analyze and benchmark models\n","def analyze_benchmark_ST(board_name,model_name):\n","  activation_size,weights_size,macc,rom_size,ram_size,execution_time=[], [], [], [], [], []\n","  for i in range(len(model_name)):\n","    analyzing=ai.analyze(CliParameters(model=model_name[i]))\n","    activation_size.append(analyzing.activations_size)\n","    weights_size.append(analyzing.weights)\n","    macc.append(analyzing.macc)\n","    rom_size.append(analyzing.rom_size)\n","    ram_size.append(analyzing.ram_size)\n","    benchamrking=ai.benchmark(CliParameters(model = model_name[i]), board_name)\n","    execution_time.append(benchamrking.graph['exec_time']['duration_ms'])\n","  return [activation_size,weights_size,macc,rom_size,ram_size,execution_time]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VQHmRuJ4j5a"},"outputs":[],"source":["##### benchmark and analyze models\n","def process_models_st(models_number,base_file_name,models_name,model_type):\n","  tflite_model_names=upload_model(models_number,base_file_name,models_name)\n","  data_tflite_board1,data_tflite_board2,data_tflite_board3,data_tflite_board4=[],[],[],[]\n","  print(\"models names\",tflite_model_names)\n","\n","  ######### benchmark and analyze dynamic quantized model with 'B_U585I_IOT02A' 4\n","  B_U585I_IOT02A_tflite_models_results=analyze_benchmark_ST(boards[4].name,tflite_model_names)\n","  headers=[\"models\",\"activation_size\",\"weights_size\",\"macc\",\"rom_size\",\"ram_size\",\"execution_time\"]\n","  data_tflite_board1=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n","  data_tflite_board1.extend(B_U585I_IOT02A_tflite_models_results)\n","\n","  ######### benchmark and analyze dynamic quantized model with 'STM32F469I-DISCO' 0\n","  STM32F469I_DISCO_tflite_models_results=analyze_benchmark_ST(boards[0].name,tflite_model_names)\n","  data_tflite_board2=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n","  data_tflite_board2.extend(STM32F469I_DISCO_tflite_models_results)\n","\n","  ######### benchmark and analyze dynamic quantized model with  'STM32L4R9I-DISCO' 1\n","  STM32L4R9I_DISCO_tflite_models_results=analyze_benchmark_ST(boards[1].name,tflite_model_names)\n","  data_tflite_board3=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n","  data_tflite_board3.extend(STM32L4R9I_DISCO_tflite_models_results)\n","\n","  ######### benchmark and analyze dynamic quantized model with  'STM32H7B3I-DK' 2\n","  STM32H7B3I_DK_tflite_models_results=analyze_benchmark_ST(boards[2].name,tflite_model_names)\n","  data_tflite_board4=[[model_type+\" MLP model \",model_type+\" CNN model \",model_type+\" DCNN model \"]]\n","  data_tflite_board4.extend(STM32H7B3I_DK_tflite_models_results)\n","\n","  delete_model(models_number,tflite_model_names)\n","  print(\"B-U585I-IOT02A\")\n","  print_table(data_tflite_board1,headers)\n","  print(\"STM32F469I-DISCO\")\n","  print_table(data_tflite_board2,headers)\n","  print(\"STM32L4R9I-DISCO\")\n","  print_table(data_tflite_board3,headers)\n","  print(\"STM32H7B3I-D\")\n","  print_table(data_tflite_board4,headers)\n","  return B_U585I_IOT02A_tflite_models_results, STM32F469I_DISCO_tflite_models_results,STM32L4R9I_DISCO_tflite_models_results,STM32H7B3I_DK_tflite_models_results,data_tflite_board1,data_tflite_board2,data_tflite_board3,data_tflite_board4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9JSxSC0djKe"},"outputs":[],"source":["############# tflite model hardware analysis and benchmarking\n","B_U585I_IOT02A_tflite_models_result, STM32F469I_DISCO_tflite_models_result,STM32L4R9I_DISCO_tflite_models_result,STM32H7B3I_DK_tflite_models_result,data_tflite_model_board1,data_tflite_model_board2,data_tflite_model_board3,data_tflite_model_board4=process_models_st(3,base_filename_model_tflite,tflite_modelfiles_best,\"tflite\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KHmwqkAa6Y2N"},"outputs":[],"source":["############# dynamic quantized tflite model hardware analysis and benchmarking\n","B_U585I_IOT02A_dynamic_quantized_tflite_models_result, STM32F469I_DISCO_dynamic_quantized_tflite_models_result,STM32L4R9I_DISCO_dynamic_quantized_tflite_models_result,STM32H7B3I_DK_dynamic_quantized_tflite_models_result,data_dynamic_model_board1,data_dynamic_model_board2,data_dynamic_model_board3,data_dynamic_model_board4=process_models_st(3,base_filename_dynamic,dynamic_modelfiles_best,\"dynamic quantized tflite\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sf0Nzd2X6z6_"},"outputs":[],"source":["############# static quantized tflite model hardware analysis and benchmarking\n","B_U585I_IOT02A_static_quantized_tflite_models_result, STM32F469I_DISCO_static_quantized_tflite_models_result,STM32L4R9I_DISCO_static_quantized_tflite_models_result,STM32H7B3I_DK_static_quantized_tflite_models_result,data_static_model_board1,data_static_model_board2,data_static_model_board3,data_static_model_board4=process_models_st(3,base_filename_static,static_modelfiles_best,\"static quantized tflite\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LBXkRi-SHSr9"},"outputs":[],"source":["############# aware quantized tflite model hardware analysis and benchmarking\n","B_U585I_IOT02A_aware_quantized_tflite_models_result, STM32F469I_DISCO_aware_quantized_tflite_models_result,STM32L4R9I_DISCO_aware_quantized_tflite_models_result,STM32H7B3I_DK_aware_quantized_tflite_models_result,data_aware_model_board1,data_aware_board2,data_aware_model_board3,data_aware_model_board4=process_models_st(3,base_filename_aware,tflite_aware_quantized_model_files,\"aware quantized tflite\")\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["FZvDBg5SqxMY","w2ou5uc7qxMe","4HZGKYdNZNn4","f5K1DhoXXy2o","Zh8j8vb_Ojxv","187VlSXQXy2x","AJ29ZnS4O_eH","GccTxLr9PKkR","0qZ4eHSLXy2x","MHN6N68et-_P","oyKybPUZG-RV","QL1DrH7wjPfC","uF562MkZjPfG","J4dgcL2Xd8Bx","JfPtfsRjyyTf","DBaWG5NBzbtU","UUU_a3XeqxMq","8JRZqEpUqxMr","xLvlcFezxB7z","VnsT3qFDjPfP","V3_niyOBqxMt","HmCqpGjTf-DT","aU0BlqEQjPfU","3ffK-qn1EZE3","1-X3Yp3epgXt"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"nav_menu":{"height":"279px","width":"309px"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false}},"nbformat":4,"nbformat_minor":0}
